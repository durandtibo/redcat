{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#contributing","title":"Contributing","text":"<p>Please check the instructions in CONTRIBUTING.md.</p>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>redcat</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>redcat</code> to a new version will possibly break any code that was using the old version of <code>redcat</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>redcat</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p> <p>The logo was generated with Fooocus</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install redcat\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>redcat</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'redcat[all]'\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>redcat</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/redcat.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate redcat\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>redcat</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"ops/batchedarray/","title":"BatchedArray","text":"<p>This page shows the supported operations for <code>BatchedArray</code> and <code>BatchedArraySeq</code></p>"},{"location":"ops/batchedarray/#core-functionalities","title":"Core functionalities","text":"name <code>BatchedArray</code> <code>BatchedArraySeq</code> <code>batch_size</code> <code>data</code> <code>allclose</code> <code>allequal</code> <code>append</code> <code>chunk_along_batch</code> <code>clone</code> <code>extend</code> <code>get_num_minibatches</code> <code>index_select_along_batch</code> <code>permute_along_batch</code> <code>permute_along_batch_</code> <code>select_along_batch</code> <code>shuffle_along_batch</code> <code>shuffle_along_batch_</code> <code>slice_along_batch</code> <code>split_along_batch</code> <code>summary</code> <code>to_data</code> <code>to_minibatches</code>"},{"location":"ops/batchedarray/#array-creation","title":"Array creation","text":"name <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> <code>array</code> <code>copy</code> <code>empty</code> <code>empty_like</code> <code>full</code> <code>full_like</code> <code>ones</code> <code>ones_like</code> <code>zeros</code> <code>zeros_like</code>"},{"location":"ops/batchedarray/#logic-functions","title":"Logic functions","text":"<p>doc</p> name <code>np</code> <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> Comparison <code>__eq__</code> <code>__ge__</code> <code>__gt__</code> <code>__le__</code> <code>__lt__</code> <code>__ne__</code> <code>allclose</code> <code>array_equal</code> <code>array_equiv</code> <code>equal</code> <code>greater_equal</code> <code>greater</code> <code>less_equal</code> <code>less</code> <code>not_equal</code> Array contents <code>isclose</code> <code>isfinite</code> <code>isinf</code> <code>isnan</code> <code>isnat</code> <code>isneginf</code> <code>isposinf</code> Logical operations <code>logical_and</code> <code>logical_not</code> <code>logical_or</code> <code>logical_xor</code>"},{"location":"ops/batchedarray/#array-manipulation","title":"Array manipulation","text":"<p>doc</p> name <code>redcat.np</code> <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> <code>__getitem__</code> <code>__setitem__</code> Joining arrays <code>concatenate</code> <code>concatenate_</code> <code>concatenate_along_batch</code> <code>concatenate_along_batch_</code> <code>concatenate_along_seq</code> <code>concatenate_along_seq_</code> Slicing arrays <code>chunk</code> <code>index_select</code> <code>select</code> <code>slice_along_axis</code> <code>slice_along_seq</code> <code>split_along_axis</code> <code>split_along_seq</code> Rearranging elements <code>permute_along_axis</code> <code>permute_along_axis_</code> <code>permute_along_seq</code> <code>permute_along_seq_</code> <code>shuffle_along_axis</code> <code>shuffle_along_axis_</code> <code>shuffle_along_seq</code> <code>shuffle_along_seq_</code>"},{"location":"ops/batchedarray/#math","title":"Math","text":"<p>doc</p> name <code>np</code> <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> Arithmetic <code>__add__</code> <code>__iadd__</code> <code>__floordiv__</code> <code>__ifloordiv__</code> <code>__mul__</code> <code>__imul__</code> <code>__neg__</code> <code>__sub__</code> <code>__isub__</code> <code>__truediv__</code> <code>__itruediv__</code> <code>add</code> <code>add_</code> <code>divide</code> <code>divmod</code> <code>divmod_</code> <code>floordiv</code> <code>floordiv_</code> <code>floor_divide</code> <code>fmod</code> <code>fmod_</code> <code>mul</code> <code>mul_</code> <code>multiply</code> <code>sub</code> <code>sub_</code> <code>substract</code> <code>truediv</code> <code>truediv_</code> <code>true_divide</code> Sums, products, differences <code>cumprod_along_batch</code> <code>cumprod_along_seq</code> <code>cumprod</code> <code>cumsum_along_batch</code> <code>cumsum_along_seq</code> <code>cumsum</code> <code>diff_along_batch</code> <code>diff_along_seq</code> <code>diff</code> <code>nancumprod_along_batch</code> <code>nancumprod_along_seq</code> <code>nancumprod</code> <code>nancumsum_along_batch</code> <code>nancumsum_along_seq</code> <code>nancumsum</code> <code>nanprod_along_batch</code> <code>nanprod_along_seq</code> <code>nanprod</code> <code>nansum_along_batch</code> <code>nansum_along_seq</code> <code>nansum</code> <code>prod_along_batch</code> <code>prod_along_seq</code> <code>prod</code> <code>sum_along_batch</code> <code>sum_along_seq</code> <code>sum</code> <code>trapz</code> Trigonometric functions Hyperbolic functions Exponents and logarithms Rounding Floating point routines Rational routines Extrema Finding <code>fmax</code> <code>fmin</code> <code>max_along_batch</code> <code>max_along_seq</code> <code>max</code> <code>maximum</code> <code>min_along_batch</code> <code>min_along_seq</code> <code>min</code> <code>minimum</code> <code>nanmax_along_batch</code> <code>nanmax_along_seq</code> <code>nanmax</code> <code>nanmin_along_batch</code> <code>nanmin_along_seq</code> <code>nanmin</code>"},{"location":"ops/batchedarray/#sorting-searching-and-counting","title":"Sorting, searching, and counting","text":"name <code>np</code> <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> Sorting <code>argsort_along_batch</code> <code>argsort_along_seq</code> <code>argsort</code> <code>sort_along_batch</code> <code>sort_along_seq</code> <code>sort</code> Searching <code>argmax_along_batch</code> <code>argmax_along_seq</code> <code>argmax</code> <code>argmin_along_batch</code> <code>argmin_along_seq</code> <code>argmin</code> <code>nanargmax_along_batch</code> <code>nanargmax_along_seq</code> <code>nanargmax</code> <code>nanargmin_along_batch</code> <code>nanargmin_along_seq</code> <code>nanargmin</code>"},{"location":"ops/batchedarray/#statistics","title":"Statistics","text":"name <code>np</code> <code>redcat.ba</code> <code>BatchedArray</code> <code>BatchedArraySeq</code> <code>mean_along_batch</code> <code>mean_along_seq</code> <code>mean</code> <code>median_along_batch</code> <code>median_along_seq</code> <code>median</code> <code>nanmean_along_batch</code> <code>nanmean_along_seq</code> <code>nanmean</code> <code>nanmedian_along_batch</code> <code>nanmedian_along_seq</code> <code>nanmedian</code> <code>nanquantile_along_batch</code> <code>nanquantile_along_seq</code> <code>nanquantile</code> <code>nanstd_along_batch</code> <code>nanstd_along_seq</code> <code>nanstd</code> <code>nanvar_along_batch</code> <code>nanvar_along_seq</code> <code>nanvar</code> <code>quantile_along_batch</code> <code>quantile_along_seq</code> <code>quantile</code> <code>std_along_batch</code> <code>std_along_seq</code> <code>std</code> <code>var_along_batch</code> <code>var_along_seq</code> <code>var</code>"},{"location":"refs/base/","title":"Base classes","text":""},{"location":"refs/base/#redcat.BaseBatch","title":"redcat.BaseBatch","text":"<p>               Bases: <code>Generic[T]</code>, <code>ABC</code></p> <p>Define the base class to implement a batch.</p>"},{"location":"refs/base/#redcat.BaseBatch.batch_size","title":"redcat.BaseBatch.batch_size  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>batch_size: int\n</code></pre> <p>The batch size.</p>"},{"location":"refs/base/#redcat.BaseBatch.data","title":"redcat.BaseBatch.data  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>data: T\n</code></pre> <p>The data in the batch.</p>"},{"location":"refs/base/#redcat.BaseBatch.allclose","title":"redcat.BaseBatch.allclose  <code>abstractmethod</code>","text":"<pre><code>allclose(\n    other: Any,\n    rtol: float = 1e-05,\n    atol: float = 1e-08,\n    equal_nan: bool = False,\n) -&gt; bool\n</code></pre> <p>Indicate if two batches are equal within a tolerance or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>Specifies the value to compare.</p> required <code>rtol</code> <code>float</code> <p>Specifies the relative tolerance parameter.</p> <code>1e-05</code> <code>atol</code> <code>float</code> <p>Specifies the absolute tolerance parameter.</p> <code>1e-08</code> <code>equal_nan</code> <code>bool</code> <p>If <code>True</code>, then two <code>NaN</code>s will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the batches are equal within a tolerance, <code>False</code> otherwise.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch1 = BatchedArray(torch.ones(2, 3))\n&gt;&gt;&gt; batch2 = BatchedArray(torch.full((2, 3), 1.5))\n&gt;&gt;&gt; batch1.allclose(batch2, atol=1, rtol=0)\nTrue\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.allequal","title":"redcat.BaseBatch.allequal  <code>abstractmethod</code>","text":"<pre><code>allequal(other: Any) -&gt; bool\n</code></pre> <p>Indicate if two batches are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>Specifies the value to compare.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the batches have the same size, elements and same batch dimension, <code>False</code> otherwise.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; BatchedArray(torch.ones(2, 3)).allequal(BatchedArray(torch.zeros(2, 3)))\nFalse\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.append","title":"redcat.BaseBatch.append  <code>abstractmethod</code>","text":"<pre><code>append(other: BaseBatch) -&gt; None\n</code></pre> <p>Append a new batch to the current batch along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BaseBatch</code> <p>Specifies the batch to append at the end of current batch.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.ones((2, 3)))\n&gt;&gt;&gt; batch.append(BatchedArray(np.zeros((1, 3))))\n&gt;&gt;&gt; batch.append(BatchedArray(np.full((1, 3), 2.0)))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [0., 0., 0.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.chunk_along_batch","title":"redcat.BaseBatch.chunk_along_batch  <code>abstractmethod</code>","text":"<pre><code>chunk_along_batch(chunks: int) -&gt; tuple[Self, ...]\n</code></pre> <p>Split the batch into chunks along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>int</code> <p>Specifies the number of chunks.</p> required <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The batch split into chunks along the batch dimension.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the number of chunks is incorrect</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).chunk_along_batch(\n...     chunks=3\n... )\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.clone","title":"redcat.BaseBatch.clone  <code>abstractmethod</code>","text":"<pre><code>clone() -&gt; Self\n</code></pre> <p>Create a copy of the current batch.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the current batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.ones((2, 3)))\n&gt;&gt;&gt; batch_copy = batch.clone()\n&gt;&gt;&gt; batch_copy\narray([[1., 1., 1.], [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.extend","title":"redcat.BaseBatch.extend  <code>abstractmethod</code>","text":"<pre><code>extend(other: Iterable[BaseBatch]) -&gt; None\n</code></pre> <p>Extend the current batch by appending all the batches from the iterable.</p> <p>This method should be used with batches of similar nature. For example, it is possible to extend a batch representing data as <code>torch.Tensor</code> by another batch representing data as <code>torch.Tensor</code>, but it is usually not possible to extend a batch representing data <code>torch.Tensor</code> by a batch representing data with a dictionary. Please check each implementation to know the supported batch implementations.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Iterable[BaseBatch]</code> <p>Specifies the batches to append to the current batch.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>if there is no available implementation for the input batch type.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.ones((2, 3)))\n&gt;&gt;&gt; batch.extend([BatchedArray(np.zeros((1, 3))), BatchedArray(np.full((1, 3), 2.0))])\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [0., 0., 0.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.get_num_minibatches","title":"redcat.BaseBatch.get_num_minibatches","text":"<pre><code>get_num_minibatches(\n    batch_size: int, drop_last: bool = False\n) -&gt; int\n</code></pre> <p>Get the number of mini-batches for a given batch size.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Specifies the target batch size of the mini-batches.</p> required <code>drop_last</code> <code>bool</code> <p>If <code>True</code>, the last batch is dropped if it is not full, otherwise it is returned.</p> <code>False</code> <p>Returns:</p> Type Description <code>int</code> <p>The number of mini-batches.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10))\n&gt;&gt;&gt; batch.get_num_minibatches(batch_size=4)\n3\n&gt;&gt;&gt; batch.get_num_minibatches(batch_size=4, drop_last=True)\n2\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.index_select_along_batch","title":"redcat.BaseBatch.index_select_along_batch  <code>abstractmethod</code>","text":"<pre><code>index_select_along_batch(\n    index: Tensor | Sequence[int],\n) -&gt; BaseBatch\n</code></pre> <p>Select data at the given indices along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>Tensor | Sequence[int]</code> <p>Specifies the indices to select.</p> required <p>Returns:</p> Type Description <code>BaseBatch</code> <p>A new batch which indexes <code>self</code> along the batch dimension using the entries in <code>index</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]))\n&gt;&gt;&gt; batch.index_select_along_batch([2, 4])\narray([[4, 5], [8, 9]], batch_axis=0)\n&gt;&gt;&gt; batch.index_select_along_batch(np.array([4, 3, 2, 1, 0]))\narray([[8, 9],\n       [6, 7],\n       [4, 5],\n       [2, 3],\n       [0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.permute_along_batch","title":"redcat.BaseBatch.permute_along_batch  <code>abstractmethod</code>","text":"<pre><code>permute_along_batch(\n    permutation: Sequence[int] | Tensor,\n) -&gt; Self\n</code></pre> <p>Permutes the data/batch along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>Sequence[int] | Tensor</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with permuted data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]))\n&gt;&gt;&gt; batch.permute_along_batch([2, 1, 3, 0, 4])\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.permute_along_batch_","title":"redcat.BaseBatch.permute_along_batch_  <code>abstractmethod</code>","text":"<pre><code>permute_along_batch_(\n    permutation: Sequence[int] | Tensor,\n) -&gt; None\n</code></pre> <p>Permutes the data/batch along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>Sequence[int] | Tensor</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]))\n&gt;&gt;&gt; batch.permute_along_batch_([2, 1, 3, 0, 4])\n&gt;&gt;&gt; batch\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.select_along_batch","title":"redcat.BaseBatch.select_along_batch","text":"<pre><code>select_along_batch(index: int) -&gt; T\n</code></pre> <p>Select the batch along the batch dimension at the given index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Specifies the index to select.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The batch sliced along the batch dimension at the given index.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).select_along_batch(2)\narray([4, 5])\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.shuffle_along_batch","title":"redcat.BaseBatch.shuffle_along_batch","text":"<pre><code>shuffle_along_batch(\n    generator: Generator | None = None,\n) -&gt; Self\n</code></pre> <p>Shuffles the data/batch along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator | None</code> <p>Specifies an optional pseudo random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with shuffled data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]))\n&gt;&gt;&gt; batch.shuffle_along_batch()\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.shuffle_along_batch_","title":"redcat.BaseBatch.shuffle_along_batch_","text":"<pre><code>shuffle_along_batch_(\n    generator: Generator | None = None,\n) -&gt; None\n</code></pre> <p>Shuffles the data/batch along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator | None</code> <p>Specifies an optional pseudo random number generator.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]))\n&gt;&gt;&gt; batch.shuffle_along_batch_()\n&gt;&gt;&gt; batch\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.slice_along_batch","title":"redcat.BaseBatch.slice_along_batch  <code>abstractmethod</code>","text":"<pre><code>slice_along_batch(\n    start: int = 0, stop: int | None = None, step: int = 1\n) -&gt; Self\n</code></pre> <p>Slices the batch in the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int</code> <p>Specifies the index where the slicing of object starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing of object stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A slice of the current batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).slice_along_batch(\n...     start=2\n... )\narray([[4, 5],\n       [6, 7],\n       [8, 9]], batch_axis=0)\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).slice_along_batch(\n...     stop=3\n... )\narray([[0, 1],\n       [2, 3],\n       [4, 5]], batch_axis=0)\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).slice_along_batch(\n...     step=2\n... )\narray([[0, 1],\n       [4, 5],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.split_along_batch","title":"redcat.BaseBatch.split_along_batch  <code>abstractmethod</code>","text":"<pre><code>split_along_batch(\n    split_size_or_sections: int | Sequence[int],\n) -&gt; tuple[Self, ...]\n</code></pre> <p>Split the batch into chunks along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>split_size_or_sections</code> <code>int | Sequence[int]</code> <p>Specifies the size of a single chunk or list of sizes for each chunk.</p> required <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The batch split into chunks along the batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; BatchedArray(np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])).split_along_batch(2)\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.summary","title":"redcat.BaseBatch.summary  <code>abstractmethod</code>","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Return a summary of the current batch.</p> <p>Returns:</p> Type Description <code>str</code> <p>The summary of the current batch</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.ones((10, 2)))\n&gt;&gt;&gt; print(batch.summary())\nBatchedArray(dtype=float64, shape=(10, 2), batch_axis=0)\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.to_data","title":"redcat.BaseBatch.to_data  <code>abstractmethod</code>","text":"<pre><code>to_data() -&gt; Any\n</code></pre> <p>Return the internal data without the batch wrapper.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The internal data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.ones((2, 3)))\n&gt;&gt;&gt; data = batch.to_data()\n&gt;&gt;&gt; data\narray([[1., 1., 1.], [1., 1., 1.]])\n</code></pre>"},{"location":"refs/base/#redcat.BaseBatch.to_minibatches","title":"redcat.BaseBatch.to_minibatches","text":"<pre><code>to_minibatches(\n    batch_size: int,\n    drop_last: bool = False,\n    deepcopy: bool = False,\n) -&gt; Iterable[Self]\n</code></pre> <p>Get the mini-batches of the current batch.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Specifies the target batch size of the mini-batches.</p> required <code>drop_last</code> <code>bool</code> <p>If <code>True</code>, the last batch is dropped if it is not full, otherwise it is returned.</p> <code>False</code> <code>deepcopy</code> <code>bool</code> <p>If <code>True</code>, a deepcopy of the batch is performed before to return the mini-batches. If <code>False</code>, each chunk is a view of the original batch/tensor. Using deepcopy allows a deterministic behavior when in-place operations are performed on the data.</p> <code>False</code> <p>Returns:</p> Type Description <code>Iterable[Self]</code> <p>The mini-batches.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(20).reshape(10, 2))\n&gt;&gt;&gt; list(batch.to_minibatches(batch_size=4))\n[array([[0, 1],\n        [2, 3],\n        [4, 5],\n        [6, 7]], batch_axis=0),\n array([[ 8,  9],\n        [10, 11],\n        [12, 13],\n        [14, 15]], batch_axis=0),\n array([[16, 17],\n        [18, 19]], batch_axis=0)]\n&gt;&gt;&gt; list(batch.to_minibatches(batch_size=4, drop_last=True))\n[array([[0, 1],\n        [2, 3],\n        [4, 5],\n        [6, 7]], batch_axis=0),\n array([[ 8,  9],\n        [10, 11],\n        [12, 13],\n        [14, 15]], batch_axis=0)]\n</code></pre>"},{"location":"refs/batchdict/","title":"BatchDict","text":""},{"location":"refs/batchdict/#redcat.BatchDict","title":"redcat.BatchDict","text":"<p>               Bases: <code>BaseBatch[dict[Hashable, TBaseBatch]]</code></p> <p>Implement a batch object to represent a dictionary of batches.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[Hashable, TBaseBatch]</code> <p>Specifies the dictionary of batches.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch\nBatchDict(\n  (key1): tensor([[0, 1, 2, 3, 4],\n            [5, 6, 7, 8, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.cat_along_seq","title":"redcat.BatchDict.cat_along_seq","text":"<pre><code>cat_along_seq(\n    batches: TBaseBatch | Sequence[TBaseBatch],\n) -&gt; Self\n</code></pre> <p>Concatenates the data of the batches to the current batch along the sequence dimension and creates a new batch.</p> <p>Note that only the sequences are concatenated.</p> <p>Parameters:</p> Name Type Description Default <code>batches</code> <code>TBaseBatch | Sequence[TBaseBatch]</code> <p>Specifies the batches to concatenate along the sequence dimension.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A batch with the concatenated data along the sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.cat_along_seq(\n...     BatchDict({\"key1\": BatchedTensorSeq(torch.tensor([[10, 11, 12], [20, 21, 22]]))})\n... )\nBatchDict(\n  (key1): tensor([[ 0,  1,  2,  3,  4, 10, 11, 12],\n            [ 5,  6,  7,  8,  9, 20, 21, 22]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.cat_along_seq_","title":"redcat.BatchDict.cat_along_seq_","text":"<pre><code>cat_along_seq_(\n    batches: TBaseBatch | Sequence[TBaseBatch],\n) -&gt; None\n</code></pre> <p>Concatenates the data of the batches to the current batch along the sequence dimension and creates a new batch.</p> <p>Note that only the sequences are concatenated.</p> <p>Parameters:</p> Name Type Description Default <code>batches</code> <code>TBaseBatch | Sequence[TBaseBatch]</code> <p>Specifies the batches to concatenate along the sequence dimension.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.cat_along_seq_(\n...     BatchDict({\"key1\": BatchedTensorSeq(torch.tensor([[10, 11, 12], [20, 21, 22]]))})\n... )\n&gt;&gt;&gt; batch\nBatchDict(\n  (key1): tensor([[ 0,  1,  2,  3,  4, 10, 11, 12],\n            [ 5,  6,  7,  8,  9, 20, 21, 22]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.index_select_along_seq","title":"redcat.BatchDict.index_select_along_seq","text":"<pre><code>index_select_along_seq(\n    index: Tensor | Sequence[int],\n) -&gt; Self\n</code></pre> <p>Slices the batch along the sequence dimension at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>Tensor | Sequence[int]</code> <p>Specifies the indices to select.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch sliced along the sequence dimension at the given indices.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.index_select_along_seq([2, 4])\nBatchDict(\n  (key1): tensor([[2, 4], [7, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n&gt;&gt;&gt; batch.index_select_along_seq(torch.tensor([2, 4]))\nBatchDict(\n  (key1): tensor([[2, 4], [7, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n&gt;&gt;&gt; batch.index_select_along_seq(torch.tensor([[2, 4], [4, 3]]))\nBatchDict(\n  (key1): tensor([[2, 4], [9, 8]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.permute_along_seq","title":"redcat.BatchDict.permute_along_seq","text":"<pre><code>permute_along_seq(\n    permutation: Sequence[int] | Tensor,\n) -&gt; Self\n</code></pre> <p>Permutes the data along the sequence dimension.</p> <p>The same permutation is applied on all the sequences. This method should be called only if all the sequences have the same length.</p> <p>This method only permutes the values that implement <code>permute_along_seq</code>.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>Sequence[int] | Tensor</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with permuted data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.permute_along_seq([2, 1, 3, 0, 4])\nBatchDict(\n  (key1): tensor([[2, 1, 3, 0, 4],\n                 [7, 6, 8, 5, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.permute_along_seq_","title":"redcat.BatchDict.permute_along_seq_","text":"<pre><code>permute_along_seq_(\n    permutation: Sequence[int] | Tensor,\n) -&gt; None\n</code></pre> <p>Permutes the data along the sequence dimension.</p> <p>The same permutation is applied on all the sequences. This method should be called only if all the sequences have the same length.</p> <p>This method only permutes the values that implement <code>permute_along_seq</code>.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>Sequence[int] | Tensor</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.permute_along_seq_([2, 1, 3, 0, 4])\n&gt;&gt;&gt; batch\nBatchDict(\n  (key1): tensor([[2, 1, 3, 0, 4],\n                 [7, 6, 8, 5, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.repeat_along_seq","title":"redcat.BatchDict.repeat_along_seq","text":"<pre><code>repeat_along_seq(repeats: int) -&gt; Self\n</code></pre> <p>Repeats the batch along the sequence dimension.</p> <p>Parameters:</p> Name Type Description Default <code>repeats</code> <code>int</code> <p>Specifies the number of times to repeat the batch along the sequence dimension.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A repeated version of the input batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.repeat_along_seq(2)\nBatchDict(\n  (key1): tensor([[0, 1, 2, 3, 4, 0, 1, 2, 3, 4],\n            [5, 6, 7, 8, 9, 5, 6, 7, 8, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.shuffle_along_seq","title":"redcat.BatchDict.shuffle_along_seq","text":"<pre><code>shuffle_along_seq(\n    generator: Generator | None = None,\n) -&gt; Self\n</code></pre> <p>Shuffles the data along the sequence dimension.</p> <p>This method should be called only if all the sequences have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator | None</code> <p>Specifies an pseudo random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with shuffled data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch has multiple sequence lengths.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.shuffle_along_seq()\nBatchDict(\n  (key1): tensor([[...]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.shuffle_along_seq_","title":"redcat.BatchDict.shuffle_along_seq_","text":"<pre><code>shuffle_along_seq_(\n    generator: Generator | None = None,\n) -&gt; None\n</code></pre> <p>Shuffles the data along the sequence dimension.</p> <p>This method should be called only if all the sequences have the same length.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator | None</code> <p>Specifies an pseudo random number generator.</p> <code>None</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch has multiple sequence lengths.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.shuffle_along_seq()\n&gt;&gt;&gt; batch\nBatchDict(\n  (key1): tensor([[...]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.slice_along_seq","title":"redcat.BatchDict.slice_along_seq","text":"<pre><code>slice_along_seq(\n    start: int = 0, stop: int | None = None, step: int = 1\n) -&gt; Self\n</code></pre> <p>Slices the batch in the sequence dimension.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>int</code> <p>Specifies the index where the slicing of object starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing of object stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A slice of the current batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.slice_along_seq(start=2)\nBatchDict(\n  (key1): tensor([[2, 3, 4],\n            [7, 8, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n&gt;&gt;&gt; batch.slice_along_seq(stop=3)\nBatchDict(\n  (key1): tensor([[0, 1, 2],\n            [5, 6, 7]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n&gt;&gt;&gt; batch.slice_along_seq(step=2)\nBatchDict(\n  (key1): tensor([[0, 2, 4],\n            [5, 7, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchdict/#redcat.BatchDict.take_along_seq","title":"redcat.BatchDict.take_along_seq","text":"<pre><code>take_along_seq(\n    indices: TBaseBatch | ndarray | Tensor | Sequence,\n) -&gt; Self\n</code></pre> <p>Take values along the sequence dimension.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>TBaseBatch | ndarray | Tensor | Sequence</code> <p>Specifies the indices to take along the batch dimension.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The batch with the selected data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchDict, BatchList, BatchedTensorSeq\n&gt;&gt;&gt; batch = BatchDict(\n...     {\n...         \"key1\": BatchedTensorSeq(torch.arange(10).view(2, 5)),\n...         \"key2\": BatchList([\"a\", \"b\"]),\n...     }\n... )\n&gt;&gt;&gt; batch.take_along_seq(torch.tensor([[3, 0, 1], [2, 3, 4]]))\nBatchDict(\n  (key1): tensor([[3, 0, 1],\n            [7, 8, 9]], batch_dim=0, seq_dim=1)\n  (key2): BatchList(data=['a', 'b'])\n)\n</code></pre>"},{"location":"refs/batchedarray/","title":"BatchedArray","text":""},{"location":"refs/batchedarray/#redcat.ba.BatchedArray","title":"redcat.ba.BatchedArray","text":"<p>               Bases: <code>BaseBatch[ndarray]</code>, <code>NDArrayOperatorsMixin</code></p> <p>Implement a wrapper around a NumPy array to track the batch axis.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.batch_axis","title":"redcat.ba.BatchedArray.batch_axis  <code>property</code>","text":"<pre><code>batch_axis: int\n</code></pre> <p>The batch axis in the array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.data","title":"redcat.ba.BatchedArray.data  <code>property</code>","text":"<pre><code>data: ndarray\n</code></pre> <p>The underlying numpy array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.dtype","title":"redcat.ba.BatchedArray.dtype  <code>property</code>","text":"<pre><code>dtype: dtype\n</code></pre> <p>Data-type of the array`s elements.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.ndim","title":"redcat.ba.BatchedArray.ndim  <code>property</code>","text":"<pre><code>ndim: int\n</code></pre> <p>Number of array dimensions.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shape","title":"redcat.ba.BatchedArray.shape  <code>property</code>","text":"<pre><code>shape: tuple[int, ...]\n</code></pre> <p>Tuple of array dimensions.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.size","title":"redcat.ba.BatchedArray.size  <code>property</code>","text":"<pre><code>size: int\n</code></pre> <p>Number of elements in the array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.add","title":"redcat.ba.BatchedArray.add","text":"<pre><code>add(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; Self\n</code></pre> <p>Add the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>out = self + alpha * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the other value to add to the current batch.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to add.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the addition of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.add(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[3., 3., 3.],\n       [3., 3., 3.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.add_","title":"redcat.ba.BatchedArray.add_","text":"<pre><code>add_(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; None\n</code></pre> <p>Add the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>self += alpha * other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the other value to add to the current batch.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to add.</p> <code>1</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.add_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[3., 3., 3.],\n       [3., 3., 3.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmax","title":"redcat.ba.BatchedArray.argmax","text":"<pre><code>argmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmax()\n1\n&gt;&gt;&gt; batch.argmax(keepdims=True)\narray([[1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmax_along_batch","title":"redcat.ba.BatchedArray.argmax_along_batch","text":"<pre><code>argmax_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmax_along_batch()\narray([1, 0, 1])\n&gt;&gt;&gt; batch.argmax_along_batch(keepdims=True)\narray([[1, 0, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmin","title":"redcat.ba.BatchedArray.argmin","text":"<pre><code>argmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmin()\n0\n&gt;&gt;&gt; batch.argmin(keepdims=True)\narray([[0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmin_along_batch","title":"redcat.ba.BatchedArray.argmin_along_batch","text":"<pre><code>argmin_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmin_along_batch()\narray([0, 1, 0])\n&gt;&gt;&gt; batch.argmin_along_batch(keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argsort","title":"redcat.ba.BatchedArray.argsort","text":"<pre><code>argsort(\n    axis: SupportsIndex | None = -1,\n    kind: SortKind | None = None,\n) -&gt; None\n</code></pre> <p>Return the indices that would sort an array.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which to sort.</p> <code>-1</code> <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; array = batch.argsort()\n&gt;&gt;&gt; array\narray([[0, 2, 1],\n       [0, 1, 2]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argsort_along_batch","title":"redcat.ba.BatchedArray.argsort_along_batch","text":"<pre><code>argsort_along_batch(kind: str | None = None) -&gt; None\n</code></pre> <p>Return the indices that would sort an array along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>The indices that would sort an array along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; array = batch.argsort_along_batch()\n&gt;&gt;&gt; array\narray([[0, 1, 0],\n       [1, 0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.chunk","title":"redcat.ba.BatchedArray.chunk","text":"<pre><code>chunk(chunks: int, axis: int = 0) -&gt; tuple[Self, ...]\n</code></pre> <p>Split an array into the specified number of chunks. Each chunk is a view of the input array.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>int</code> <p>Specifies the number of chunks.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis along which to split the array.</p> <code>0</code> <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The array split into chunks along the given axis.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the number of chunks is incorrect</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.chunk(chunks=3)\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate","title":"redcat.ba.BatchedArray.concatenate","text":"<pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: int = ...,\n) -&gt; Self\n</code></pre> <pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: int | None = 0,\n) -&gt; Self | ndarray\n</code></pre> <p>Join a sequence of arrays along an existing axis.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <code>axis</code> <code>int | None</code> <p>The axis along which the arrays will be joined. If axis is None, arrays are flattened before use.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The concatenated array.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; out = batch.concatenate([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[0, 1, 2],\n       [4, 5, 6]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_","title":"redcat.ba.BatchedArray.concatenate_","text":"<pre><code>concatenate_(\n    arrays: Iterable[BatchedArray | ndarray], axis: int = 0\n) -&gt; None\n</code></pre> <p>Join a sequence of arrays along an existing axis in-place.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <code>axis</code> <code>int</code> <p>The axis along which the arrays will be joined.</p> <code>0</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; batch.concatenate_([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_along_batch","title":"redcat.ba.BatchedArray.concatenate_along_batch","text":"<pre><code>concatenate_along_batch(\n    arrays: Iterable[BatchedArray | ndarray],\n) -&gt; Self\n</code></pre> <p>Join a sequence of arrays along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The concatenated array.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; out = batch.concatenate_along_batch([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[0, 1, 2],\n       [4, 5, 6]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_along_batch_","title":"redcat.ba.BatchedArray.concatenate_along_batch_","text":"<pre><code>concatenate_along_batch_(\n    arrays: Iterable[BatchedArray | ndarray],\n) -&gt; None\n</code></pre> <p>Join a sequence of arrays along the batch axis in-place.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; batch.concatenate_along_batch_([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.copy","title":"redcat.ba.BatchedArray.copy","text":"<pre><code>copy(order: OrderACFK = 'C') -&gt; Self\n</code></pre> <p>Return a copy of the array.</p> <p>Parameters:</p> Name Type Description Default <code>order</code> <code>OrderACFK</code> <p>Controls the memory layout of the copy. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if the current array is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means  match the layout of current array as closely as possible.</p> <code>'C'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; x = array.copy()\n&gt;&gt;&gt; x += 1\n&gt;&gt;&gt; array\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; x\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumprod","title":"redcat.ba.BatchedArray.cumprod","text":"<pre><code>cumprod(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>cumprod(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>cumprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative product of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative product of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumprod(axis=0)\narray([[  0,   1],\n       [  0,   3],\n       [  0,  15],\n       [  0, 105],\n       [  0, 945]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.cumprod(axis=1)\narray([[    0,     0,     0,     0,     0],\n       [    5,    30,   210,  1680, 15120]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumprod_along_batch","title":"redcat.ba.BatchedArray.cumprod_along_batch","text":"<pre><code>cumprod_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumprod_along_batch()\narray([[  0,   1],\n       [  0,   3],\n       [  0,  15],\n       [  0, 105],\n       [  0, 945]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumsum","title":"redcat.ba.BatchedArray.cumsum","text":"<pre><code>cumsum(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>cumsum(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>cumsum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative sum of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative sum of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumsum(axis=0)\narray([[ 0,  1],\n       [ 2,  4],\n       [ 6,  9],\n       [12, 16],\n       [20, 25]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.cumsum(axis=1)\narray([[ 0,  1,  3,  6, 10],\n       [ 5, 11, 18, 26, 35]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumsum_along_batch","title":"redcat.ba.BatchedArray.cumsum_along_batch","text":"<pre><code>cumsum_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumsum_along_batch()\narray([[ 0,  1],\n       [ 2,  4],\n       [ 6,  9],\n       [12, 16],\n       [20, 25]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.diff","title":"redcat.ba.BatchedArray.diff","text":"<pre><code>diff(\n    n: int = 1,\n    axis: SupportsIndex = -1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; Self | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the given axis.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>axis</code> <code>SupportsIndex</code> <p>The axis along which the difference is taken, default is the last axis.</p> <code>-1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; batch.diff(n=1, axis=0)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; batch.diff(axis=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.diff_along_batch","title":"redcat.ba.BatchedArray.diff_along_batch","text":"<pre><code>diff_along_batch(\n    n: int = 1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; Self | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along the batch axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; batch.diff_along_batch(n=1)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; batch.diff_along_batch(n=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.empty_like","title":"redcat.ba.BatchedArray.empty_like","text":"<pre><code>empty_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array without initializing entries, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>Array of zeros with the same shape and type as <code>self</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.empty_like().shape\n(2, 3)\n&gt;&gt;&gt; array.empty_like(batch_size=5).shape\n(5, 3)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.floordiv","title":"redcat.ba.BatchedArray.floordiv","text":"<pre><code>floordiv(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Return the largest integer smaller or equal to the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The largest integer smaller or equal to the division of the inputs.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.floordiv(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.floordiv_","title":"redcat.ba.BatchedArray.floordiv_","text":"<pre><code>floordiv_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Return the largest integer smaller or equal to the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.floordiv_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.fmod","title":"redcat.ba.BatchedArray.fmod","text":"<pre><code>fmod(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Compute the element-wise remainder of division.</p> <p>The current batch is the dividend.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the element-wise remainder of division.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.fmod(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.fmod_","title":"redcat.ba.BatchedArray.fmod_","text":"<pre><code>fmod_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Compute the element-wise remainder of division.</p> <p>The current batch is the dividend.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.fmod_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.full_like","title":"redcat.ba.BatchedArray.full_like","text":"<pre><code>full_like(\n    fill_value: float | ArrayLike,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>fill_value</code> <code>float | ArrayLike</code> <p>Specifies the fill value.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.full_like(42.0)\narray([[42., 42., 42.],\n       [42., 42., 42.]], batch_axis=0)\n&gt;&gt;&gt; array.full_like(fill_value=42.0, batch_size=5)\narray([[42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.index_select","title":"redcat.ba.BatchedArray.index_select","text":"<pre><code>index_select(\n    index: ndarray | Sequence[int], axis: None = ...\n) -&gt; ndarray\n</code></pre><pre><code>index_select(\n    index: ndarray | Sequence[int], axis: int = ...\n) -&gt; Self\n</code></pre> <pre><code>index_select(\n    index: ndarray | Sequence[int], axis: int | None = None\n) -&gt; Self | ndarray\n</code></pre> <p>Return a new array which indexes the input array along the given axis using the entries in <code>index</code>.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ndarray | Sequence[int]</code> <p>The 1-D array containing the indices to index.</p> required <code>axis</code> <code>int | None</code> <p>The axis over which to select values. By default, the flattened input array is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>A new array which indexes the input array along the given axis using the entries in <code>index</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.index_select([2, 4], axis=0)\narray([[4, 5],\n       [8, 9]], batch_axis=0)\n&gt;&gt;&gt; batch.index_select(np.array([4, 3, 2, 1, 0]), axis=0)\narray([[8, 9],\n       [6, 7],\n       [4, 5],\n       [2, 3],\n       [0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.max","title":"redcat.ba.BatchedArray.max","text":"<pre><code>max(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.max()\n6\n&gt;&gt;&gt; batch.max(axis=0)\narray([3, 6, 5])\n&gt;&gt;&gt; batch.max(axis=0, keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.max(axis=1)\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.max_along_batch","title":"redcat.ba.BatchedArray.max_along_batch","text":"<pre><code>max_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.max_along_batch()\narray([3, 6, 5])\n&gt;&gt;&gt; batch.max_along_batch(keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.max_along_batch()\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mean","title":"redcat.ba.BatchedArray.mean","text":"<pre><code>mean(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the specified axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.mean()\n4.5\n&gt;&gt;&gt; batch.mean(axis=0)\narray([4., 5.])\n&gt;&gt;&gt; batch.mean(axis=0, keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.mean(axis=1)\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mean_along_batch","title":"redcat.ba.BatchedArray.mean_along_batch","text":"<pre><code>mean_along_batch(\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.mean_along_batch()\narray([4., 5.])\n&gt;&gt;&gt; batch.mean_along_batch(keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.mean_along_batch()\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.median","title":"redcat.ba.BatchedArray.median","text":"<pre><code>median(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the specified axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.median()\n4.5\n&gt;&gt;&gt; batch.median(axis=0)\narray([4., 5.])\n&gt;&gt;&gt; batch.median(axis=0, keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.median(axis=1)\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.median_along_batch","title":"redcat.ba.BatchedArray.median_along_batch","text":"<pre><code>median_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the batch axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.median_along_batch()\narray([4., 5.])\n&gt;&gt;&gt; batch.median_along_batch(keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.median_along_batch()\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.min","title":"redcat.ba.BatchedArray.min","text":"<pre><code>min(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.min()\n1\n&gt;&gt;&gt; batch.min(axis=0)\narray([1, 4, 2])\n&gt;&gt;&gt; batch.min(axis=0, keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.min(axis=1)\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.min_along_batch","title":"redcat.ba.BatchedArray.min_along_batch","text":"<pre><code>min_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.min_along_batch()\narray([1, 4, 2])\n&gt;&gt;&gt; batch.min_along_batch(keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.min_along_batch()\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mul","title":"redcat.ba.BatchedArray.mul","text":"<pre><code>mul(other: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Multiplies the <code>self</code> batch by the input <code>`other</code>.</p> <p>Similar to <code>out = self * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to multiply.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the multiplication of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.mul(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mul_","title":"redcat.ba.BatchedArray.mul_","text":"<pre><code>mul_(other: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Multiplies the <code>self</code> batch by the input <code>`other</code>.</p> <p>Similar to <code>self *= other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to multiply.</p> required <p>Returns:</p> Type Description <code>None</code> <p>A new batch containing the multiplication of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.mul_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmax","title":"redcat.ba.BatchedArray.nanargmax","text":"<pre><code>nanargmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along an axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along an axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmax()\n5\n&gt;&gt;&gt; batch.nanargmax(keepdims=True)\narray([[5]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmax_along_batch","title":"redcat.ba.BatchedArray.nanargmax_along_batch","text":"<pre><code>nanargmax_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmax_along_batch()\narray([1, 1, 1])\n&gt;&gt;&gt; batch.nanargmax_along_batch(keepdims=True)\narray([[1, 1, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmin","title":"redcat.ba.BatchedArray.nanargmin","text":"<pre><code>nanargmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along an axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along an axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmin()\n0\n&gt;&gt;&gt; batch.nanargmin(keepdims=True)\narray([[0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmin_along_batch","title":"redcat.ba.BatchedArray.nanargmin_along_batch","text":"<pre><code>nanargmin_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmin_along_batch()\narray([0, 1, 0])\n&gt;&gt;&gt; batch.nanargmin_along_batch(keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumprod","title":"redcat.ba.BatchedArray.nancumprod","text":"<pre><code>nancumprod(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>nancumprod(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>nancumprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumprod(axis=0)\narray([[ 1.,  1.,  2.],\n       [ 3.,  4., 10.]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nancumprod(axis=1)\narray([[ 1.,  1.,  2.],\n       [ 3., 12., 60.]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumprod_along_batch","title":"redcat.ba.BatchedArray.nancumprod_along_batch","text":"<pre><code>nancumprod_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumprod_along_batch()\narray([[ 1.,  1.,  2.],\n       [ 3.,  4., 10.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumsum","title":"redcat.ba.BatchedArray.nancumsum","text":"<pre><code>nancumsum(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>nancumsum(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>nancumsum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumsum(axis=0)\narray([[1., 0., 2.],\n       [4., 4., 7.]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nancumsum(axis=1)\narray([[ 1.,  1.,  3.],\n       [ 3.,  7., 12.]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumsum_along_batch","title":"redcat.ba.BatchedArray.nancumsum_along_batch","text":"<pre><code>nancumsum_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumsum_along_batch()\narray([[1., 0., 2.],\n       [4., 4., 7.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmax","title":"redcat.ba.BatchedArray.nanmax","text":"<pre><code>nanmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmax()\n5.0\n&gt;&gt;&gt; batch.nanmax(axis=0)\narray([3., 4., 5.])\n&gt;&gt;&gt; batch.nanmax(axis=0, keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmax(axis=1)\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmax_along_batch","title":"redcat.ba.BatchedArray.nanmax_along_batch","text":"<pre><code>nanmax_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmax_along_batch()\narray([3., 4., 5.])\n&gt;&gt;&gt; batch.nanmax_along_batch(keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmax_along_batch()\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmean","title":"redcat.ba.BatchedArray.nanmean","text":"<pre><code>nanmean(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmean()\n3.0\n&gt;&gt;&gt; batch.nanmean(axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmean(axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch.nanmean(axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmean_along_batch","title":"redcat.ba.BatchedArray.nanmean_along_batch","text":"<pre><code>nanmean_along_batch(\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmean_along_batch()\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmean_along_batch(keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmean_along_batch()\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmedian","title":"redcat.ba.BatchedArray.nanmedian","text":"<pre><code>nanmedian(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmedian()\n3.0\n&gt;&gt;&gt; batch.nanmedian(axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmedian(axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch.nanmedian(axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmedian_along_batch","title":"redcat.ba.BatchedArray.nanmedian_along_batch","text":"<pre><code>nanmedian_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmedian_along_batch()\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmedian_along_batch(keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmedian_along_batch()\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmin","title":"redcat.ba.BatchedArray.nanmin","text":"<pre><code>nanmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmin()\n2.0\n&gt;&gt;&gt; batch.nanmin(axis=0)\narray([3., 4., 2.])\n&gt;&gt;&gt; batch.nanmin(axis=0, keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmin(axis=1)\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmin_along_batch","title":"redcat.ba.BatchedArray.nanmin_along_batch","text":"<pre><code>nanmin_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmin_along_batch()\narray([3., 4., 2.])\n&gt;&gt;&gt; batch.nanmin_along_batch(keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmin_along_batch()\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanprod","title":"redcat.ba.BatchedArray.nanprod","text":"<pre><code>nanprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanprod(axis=0)\narray([ 3., 4., 10.])\n&gt;&gt;&gt; batch.nanprod(axis=0, keepdims=True)\narray([[ 3., 4., 10.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanprod(axis=1)\narray([ 2., 60.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanprod_along_batch","title":"redcat.ba.BatchedArray.nanprod_along_batch","text":"<pre><code>nanprod_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanprod_along_batch()\narray([ 3., 4., 10.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nansum","title":"redcat.ba.BatchedArray.nansum","text":"<pre><code>nansum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nansum(axis=0)\narray([4., 4., 7.])\n&gt;&gt;&gt; batch.nansum(axis=0, keepdims=True)\narray([[4., 4., 7.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nansum(axis=1)\narray([ 3., 12.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nansum_along_batch","title":"redcat.ba.BatchedArray.nansum_along_batch","text":"<pre><code>nansum_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nansum_along_batch()\narray([4., 4., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.neg","title":"redcat.ba.BatchedArray.neg","text":"<pre><code>neg() -&gt; Self\n</code></pre> <p>Return a new batch with the negative of the elements.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with the negative of the elements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.neg()\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.ones_like","title":"redcat.ba.BatchedArray.ones_like","text":"<pre><code>ones_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.zeros((2, 3))\n&gt;&gt;&gt; array.ones_like()\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; array.ones_like(batch_size=5)\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.permute_along_axis","title":"redcat.ba.BatchedArray.permute_along_axis","text":"<pre><code>permute_along_axis(\n    permutation: ndarray | Sequence[int], axis: int\n) -&gt; Self\n</code></pre> <p>Permute the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>ndarray | Sequence[int]</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis where the permutation is computed.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with permuted data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.permute_along_axis([2, 1, 3, 0, 4], axis=0)\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.permute_along_axis_","title":"redcat.ba.BatchedArray.permute_along_axis_","text":"<pre><code>permute_along_axis_(\n    permutation: ndarray | Sequence[int], axis: int\n) -&gt; None\n</code></pre> <p>Permutes the data/batch along a given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>ndarray | Sequence[int]</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis where the permutation is computed.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.permute_along_axis_([2, 1, 3, 0, 4], axis=0)\n&gt;&gt;&gt; batch\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.prod","title":"redcat.ba.BatchedArray.prod","text":"<pre><code>prod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the product of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The product of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.prod(axis=0)\narray([ 3, 24, 10])\n&gt;&gt;&gt; batch.prod(axis=0, keepdims=True)\narray([[ 3, 24, 10]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.prod(axis=1)\narray([12, 60])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.prod_along_batch","title":"redcat.ba.BatchedArray.prod_along_batch","text":"<pre><code>prod_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.prod_along_batch()\narray([ 3, 24, 10])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.select","title":"redcat.ba.BatchedArray.select","text":"<pre><code>select(index: int, axis: int) -&gt; ndarray\n</code></pre> <p>Select the data along the given axis at the given index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Specifies the index to select.</p> required <code>axis</code> <code>int</code> <p>Specifies the index axis.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The batch sliced along the given axis at the given index.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.select(index=2, axis=0)\narray([4, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shuffle_along_axis","title":"redcat.ba.BatchedArray.shuffle_along_axis","text":"<pre><code>shuffle_along_axis(\n    axis: int, rng: Generator | None = None\n) -&gt; Self\n</code></pre> <p>Shuffle the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the shuffle axis.</p> required <code>rng</code> <code>Generator | None</code> <p>Specifies the pseudorandom number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with shuffled data along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.shuffle_along_axis(axis=0)\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shuffle_along_axis_","title":"redcat.ba.BatchedArray.shuffle_along_axis_","text":"<pre><code>shuffle_along_axis_(\n    axis: int, rng: Generator | None = None\n) -&gt; None\n</code></pre> <p>Shuffle the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the shuffle axis.</p> required <code>rng</code> <code>Generator | None</code> <p>Specifies the pseudorandom number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A new batch with shuffled data along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.shuffle_along_axis_(axis=0)\n&gt;&gt;&gt; batch\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.slice_along_axis","title":"redcat.ba.BatchedArray.slice_along_axis","text":"<pre><code>slice_along_axis(\n    axis: int = 0,\n    start: int = 0,\n    stop: int | None = None,\n    step: int = 1,\n) -&gt; Self\n</code></pre> <p>Slice the batch in a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the axis along which to slice the array.</p> <code>0</code> <code>start</code> <code>int</code> <p>Specifies the index where the slicing starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A slice of the current batch along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.slice_along_axis(start=2)\narray([[4, 5],\n       [6, 7],\n       [8, 9]], batch_axis=0)\n&gt;&gt;&gt; batch.slice_along_axis(stop=3)\narray([[0, 1],\n       [2, 3],\n       [4, 5]], batch_axis=0)\n&gt;&gt;&gt; batch.slice_along_axis(step=2)\narray([[0, 1],\n       [4, 5],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sort","title":"redcat.ba.BatchedArray.sort","text":"<pre><code>sort(\n    axis: SupportsIndex | None = -1,\n    kind: SortKind | None = None,\n) -&gt; None\n</code></pre> <p>Sort an array in-place.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which to sort.</p> <code>-1</code> <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sort()\n&gt;&gt;&gt; batch\narray([[1, 2, 6],\n       [3, 4, 5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sort_along_batch","title":"redcat.ba.BatchedArray.sort_along_batch","text":"<pre><code>sort_along_batch(kind: str | None = None) -&gt; None\n</code></pre> <p>Sort an array in-place along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sort_along_batch()\n&gt;&gt;&gt; batch\narray([[1, 4, 2],\n       [3, 6, 5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.split_along_axis","title":"redcat.ba.BatchedArray.split_along_axis","text":"<pre><code>split_along_axis(\n    split_size_or_sections: int | Sequence[int],\n    axis: int = 0,\n) -&gt; tuple[Self, ...]\n</code></pre> <p>Split the batch into chunks along a given axis.</p> Notes <p>This function has a slightly different behavior as     <code>numpy.split</code>.</p> <p>Parameters:</p> Name Type Description Default <code>split_size_or_sections</code> <code>int | Sequence[int]</code> <p>Specifies the size of a single chunk or list of sizes for each chunk.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis along which to split the array.</p> <code>0</code> <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The batch split into chunks along the given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.split_along_axis(2, axis=0)\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sub","title":"redcat.ba.BatchedArray.sub","text":"<pre><code>sub(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; Self\n</code></pre> <p>Subtracts the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>out = self - alpha * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to subtract.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to substract.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the diffence of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.sub(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sub_","title":"redcat.ba.BatchedArray.sub_","text":"<pre><code>sub_(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; None\n</code></pre> <p>Subtracts the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>self -= alpha * other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to subtract.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to substract.</p> <code>1</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.sub_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sum","title":"redcat.ba.BatchedArray.sum","text":"<pre><code>sum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the sum of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The sum of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sum(axis=0)\narray([ 4, 10, 7])\n&gt;&gt;&gt; batch.sum(axis=0, keepdims=True)\narray([[ 4, 10, 7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.sum(axis=1)\narray([ 9, 12])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sum_along_batch","title":"redcat.ba.BatchedArray.sum_along_batch","text":"<pre><code>sum_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sum_along_batch()\narray([ 4, 10, 7])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.truediv","title":"redcat.ba.BatchedArray.truediv","text":"<pre><code>truediv(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Return the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The division of the inputs.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.truediv(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[0.5, 0.5, 0.5],\n       [0.5, 0.5, 0.5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.truediv_","title":"redcat.ba.BatchedArray.truediv_","text":"<pre><code>truediv_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Return the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.truediv_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[0.5, 0.5, 0.5],\n       [0.5, 0.5, 0.5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.zeros_like","title":"redcat.ba.BatchedArray.zeros_like","text":"<pre><code>zeros_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>0</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>0</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.zeros_like()\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n&gt;&gt;&gt; array.zeros_like(batch_size=5)\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba","title":"redcat.ba","text":"<p>Contain the implementation of <code>BatchedArray</code> and its associated functions.</p> <p><code>BatchedArray</code> is a custom NumPy array container to make batch manipulation easier.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray","title":"redcat.ba.BatchedArray","text":"<p>               Bases: <code>BaseBatch[ndarray]</code>, <code>NDArrayOperatorsMixin</code></p> <p>Implement a wrapper around a NumPy array to track the batch axis.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.batch_axis","title":"redcat.ba.BatchedArray.batch_axis  <code>property</code>","text":"<pre><code>batch_axis: int\n</code></pre> <p>The batch axis in the array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.data","title":"redcat.ba.BatchedArray.data  <code>property</code>","text":"<pre><code>data: ndarray\n</code></pre> <p>The underlying numpy array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.dtype","title":"redcat.ba.BatchedArray.dtype  <code>property</code>","text":"<pre><code>dtype: dtype\n</code></pre> <p>Data-type of the array`s elements.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.ndim","title":"redcat.ba.BatchedArray.ndim  <code>property</code>","text":"<pre><code>ndim: int\n</code></pre> <p>Number of array dimensions.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shape","title":"redcat.ba.BatchedArray.shape  <code>property</code>","text":"<pre><code>shape: tuple[int, ...]\n</code></pre> <p>Tuple of array dimensions.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.size","title":"redcat.ba.BatchedArray.size  <code>property</code>","text":"<pre><code>size: int\n</code></pre> <p>Number of elements in the array.</p>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.add","title":"redcat.ba.BatchedArray.add","text":"<pre><code>add(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; Self\n</code></pre> <p>Add the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>out = self + alpha * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the other value to add to the current batch.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to add.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the addition of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.add(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[3., 3., 3.],\n       [3., 3., 3.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.add_","title":"redcat.ba.BatchedArray.add_","text":"<pre><code>add_(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; None\n</code></pre> <p>Add the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>self += alpha * other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the other value to add to the current batch.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to add.</p> <code>1</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.add_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[3., 3., 3.],\n       [3., 3., 3.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmax","title":"redcat.ba.BatchedArray.argmax","text":"<pre><code>argmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmax()\n1\n&gt;&gt;&gt; batch.argmax(keepdims=True)\narray([[1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmax_along_batch","title":"redcat.ba.BatchedArray.argmax_along_batch","text":"<pre><code>argmax_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmax_along_batch()\narray([1, 0, 1])\n&gt;&gt;&gt; batch.argmax_along_batch(keepdims=True)\narray([[1, 0, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmin","title":"redcat.ba.BatchedArray.argmin","text":"<pre><code>argmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmin()\n0\n&gt;&gt;&gt; batch.argmin(keepdims=True)\narray([[0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argmin_along_batch","title":"redcat.ba.BatchedArray.argmin_along_batch","text":"<pre><code>argmin_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.argmin_along_batch()\narray([0, 1, 0])\n&gt;&gt;&gt; batch.argmin_along_batch(keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argsort","title":"redcat.ba.BatchedArray.argsort","text":"<pre><code>argsort(\n    axis: SupportsIndex | None = -1,\n    kind: SortKind | None = None,\n) -&gt; None\n</code></pre> <p>Return the indices that would sort an array.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which to sort.</p> <code>-1</code> <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; array = batch.argsort()\n&gt;&gt;&gt; array\narray([[0, 2, 1],\n       [0, 1, 2]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.argsort_along_batch","title":"redcat.ba.BatchedArray.argsort_along_batch","text":"<pre><code>argsort_along_batch(kind: str | None = None) -&gt; None\n</code></pre> <p>Return the indices that would sort an array along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>The indices that would sort an array along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; array = batch.argsort_along_batch()\n&gt;&gt;&gt; array\narray([[0, 1, 0],\n       [1, 0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.chunk","title":"redcat.ba.BatchedArray.chunk","text":"<pre><code>chunk(chunks: int, axis: int = 0) -&gt; tuple[Self, ...]\n</code></pre> <p>Split an array into the specified number of chunks. Each chunk is a view of the input array.</p> <p>Parameters:</p> Name Type Description Default <code>chunks</code> <code>int</code> <p>Specifies the number of chunks.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis along which to split the array.</p> <code>0</code> <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The array split into chunks along the given axis.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the number of chunks is incorrect</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.chunk(chunks=3)\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate","title":"redcat.ba.BatchedArray.concatenate","text":"<pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: int = ...,\n) -&gt; Self\n</code></pre> <pre><code>concatenate(\n    arrays: Iterable[BatchedArray | ndarray],\n    axis: int | None = 0,\n) -&gt; Self | ndarray\n</code></pre> <p>Join a sequence of arrays along an existing axis.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <code>axis</code> <code>int | None</code> <p>The axis along which the arrays will be joined. If axis is None, arrays are flattened before use.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The concatenated array.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; out = batch.concatenate([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[0, 1, 2],\n       [4, 5, 6]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_","title":"redcat.ba.BatchedArray.concatenate_","text":"<pre><code>concatenate_(\n    arrays: Iterable[BatchedArray | ndarray], axis: int = 0\n) -&gt; None\n</code></pre> <p>Join a sequence of arrays along an existing axis in-place.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <code>axis</code> <code>int</code> <p>The axis along which the arrays will be joined.</p> <code>0</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; batch.concatenate_([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_along_batch","title":"redcat.ba.BatchedArray.concatenate_along_batch","text":"<pre><code>concatenate_along_batch(\n    arrays: Iterable[BatchedArray | ndarray],\n) -&gt; Self\n</code></pre> <p>Join a sequence of arrays along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The concatenated array.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; out = batch.concatenate_along_batch([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[0, 1, 2],\n       [4, 5, 6]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.concatenate_along_batch_","title":"redcat.ba.BatchedArray.concatenate_along_batch_","text":"<pre><code>concatenate_along_batch_(\n    arrays: Iterable[BatchedArray | ndarray],\n) -&gt; None\n</code></pre> <p>Join a sequence of arrays along the batch axis in-place.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[BatchedArray | ndarray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array([[0, 1, 2], [4, 5, 6]])\n&gt;&gt;&gt; batch.concatenate_along_batch_([ba.array([[10, 11, 12], [13, 14, 15]])])\n&gt;&gt;&gt; batch\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.copy","title":"redcat.ba.BatchedArray.copy","text":"<pre><code>copy(order: OrderACFK = 'C') -&gt; Self\n</code></pre> <p>Return a copy of the array.</p> <p>Parameters:</p> Name Type Description Default <code>order</code> <code>OrderACFK</code> <p>Controls the memory layout of the copy. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if the current array is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means  match the layout of current array as closely as possible.</p> <code>'C'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; x = array.copy()\n&gt;&gt;&gt; x += 1\n&gt;&gt;&gt; array\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; x\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumprod","title":"redcat.ba.BatchedArray.cumprod","text":"<pre><code>cumprod(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>cumprod(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>cumprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative product of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative product of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumprod(axis=0)\narray([[  0,   1],\n       [  0,   3],\n       [  0,  15],\n       [  0, 105],\n       [  0, 945]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.cumprod(axis=1)\narray([[    0,     0,     0,     0,     0],\n       [    5,    30,   210,  1680, 15120]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumprod_along_batch","title":"redcat.ba.BatchedArray.cumprod_along_batch","text":"<pre><code>cumprod_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumprod_along_batch()\narray([[  0,   1],\n       [  0,   3],\n       [  0,  15],\n       [  0, 105],\n       [  0, 945]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumsum","title":"redcat.ba.BatchedArray.cumsum","text":"<pre><code>cumsum(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>cumsum(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>cumsum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative sum of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative sum of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumsum(axis=0)\narray([[ 0,  1],\n       [ 2,  4],\n       [ 6,  9],\n       [12, 16],\n       [20, 25]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.cumsum(axis=1)\narray([[ 0,  1,  3,  6, 10],\n       [ 5, 11, 18, 26, 35]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.cumsum_along_batch","title":"redcat.ba.BatchedArray.cumsum_along_batch","text":"<pre><code>cumsum_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.cumsum_along_batch()\narray([[ 0,  1],\n       [ 2,  4],\n       [ 6,  9],\n       [12, 16],\n       [20, 25]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.diff","title":"redcat.ba.BatchedArray.diff","text":"<pre><code>diff(\n    n: int = 1,\n    axis: SupportsIndex = -1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; Self | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the given axis.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>axis</code> <code>SupportsIndex</code> <p>The axis along which the difference is taken, default is the last axis.</p> <code>-1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; batch.diff(n=1, axis=0)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; batch.diff(axis=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.diff_along_batch","title":"redcat.ba.BatchedArray.diff_along_batch","text":"<pre><code>diff_along_batch(\n    n: int = 1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; Self | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along the batch axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; batch.diff_along_batch(n=1)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; batch.diff_along_batch(n=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.empty_like","title":"redcat.ba.BatchedArray.empty_like","text":"<pre><code>empty_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array without initializing entries, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>Array of zeros with the same shape and type as <code>self</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.empty_like().shape\n(2, 3)\n&gt;&gt;&gt; array.empty_like(batch_size=5).shape\n(5, 3)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.floordiv","title":"redcat.ba.BatchedArray.floordiv","text":"<pre><code>floordiv(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Return the largest integer smaller or equal to the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The largest integer smaller or equal to the division of the inputs.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.floordiv(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.floordiv_","title":"redcat.ba.BatchedArray.floordiv_","text":"<pre><code>floordiv_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Return the largest integer smaller or equal to the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.floordiv_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.fmod","title":"redcat.ba.BatchedArray.fmod","text":"<pre><code>fmod(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Compute the element-wise remainder of division.</p> <p>The current batch is the dividend.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the element-wise remainder of division.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.fmod(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.fmod_","title":"redcat.ba.BatchedArray.fmod_","text":"<pre><code>fmod_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Compute the element-wise remainder of division.</p> <p>The current batch is the dividend.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.fmod_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.full_like","title":"redcat.ba.BatchedArray.full_like","text":"<pre><code>full_like(\n    fill_value: float | ArrayLike,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>fill_value</code> <code>float | ArrayLike</code> <p>Specifies the fill value.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.full_like(42.0)\narray([[42., 42., 42.],\n       [42., 42., 42.]], batch_axis=0)\n&gt;&gt;&gt; array.full_like(fill_value=42.0, batch_size=5)\narray([[42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.],\n       [42., 42., 42.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.index_select","title":"redcat.ba.BatchedArray.index_select","text":"<pre><code>index_select(\n    index: ndarray | Sequence[int], axis: None = ...\n) -&gt; ndarray\n</code></pre><pre><code>index_select(\n    index: ndarray | Sequence[int], axis: int = ...\n) -&gt; Self\n</code></pre> <pre><code>index_select(\n    index: ndarray | Sequence[int], axis: int | None = None\n) -&gt; Self | ndarray\n</code></pre> <p>Return a new array which indexes the input array along the given axis using the entries in <code>index</code>.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>ndarray | Sequence[int]</code> <p>The 1-D array containing the indices to index.</p> required <code>axis</code> <code>int | None</code> <p>The axis over which to select values. By default, the flattened input array is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>A new array which indexes the input array along the given axis using the entries in <code>index</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.index_select([2, 4], axis=0)\narray([[4, 5],\n       [8, 9]], batch_axis=0)\n&gt;&gt;&gt; batch.index_select(np.array([4, 3, 2, 1, 0]), axis=0)\narray([[8, 9],\n       [6, 7],\n       [4, 5],\n       [2, 3],\n       [0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.max","title":"redcat.ba.BatchedArray.max","text":"<pre><code>max(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.max()\n6\n&gt;&gt;&gt; batch.max(axis=0)\narray([3, 6, 5])\n&gt;&gt;&gt; batch.max(axis=0, keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.max(axis=1)\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.max_along_batch","title":"redcat.ba.BatchedArray.max_along_batch","text":"<pre><code>max_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.max_along_batch()\narray([3, 6, 5])\n&gt;&gt;&gt; batch.max_along_batch(keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.max_along_batch()\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mean","title":"redcat.ba.BatchedArray.mean","text":"<pre><code>mean(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the specified axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.mean()\n4.5\n&gt;&gt;&gt; batch.mean(axis=0)\narray([4., 5.])\n&gt;&gt;&gt; batch.mean(axis=0, keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.mean(axis=1)\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mean_along_batch","title":"redcat.ba.BatchedArray.mean_along_batch","text":"<pre><code>mean_along_batch(\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.mean_along_batch()\narray([4., 5.])\n&gt;&gt;&gt; batch.mean_along_batch(keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.mean_along_batch()\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.median","title":"redcat.ba.BatchedArray.median","text":"<pre><code>median(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the specified axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.median()\n4.5\n&gt;&gt;&gt; batch.median(axis=0)\narray([4., 5.])\n&gt;&gt;&gt; batch.median(axis=0, keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.median(axis=1)\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.median_along_batch","title":"redcat.ba.BatchedArray.median_along_batch","text":"<pre><code>median_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the batch axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.median_along_batch()\narray([4., 5.])\n&gt;&gt;&gt; batch.median_along_batch(keepdims=True)\narray([[4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(2, 5), batch_axis=1)\n&gt;&gt;&gt; batch.median_along_batch()\narray([2., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.min","title":"redcat.ba.BatchedArray.min","text":"<pre><code>min(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.min()\n1\n&gt;&gt;&gt; batch.min(axis=0)\narray([1, 4, 2])\n&gt;&gt;&gt; batch.min(axis=0, keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.min(axis=1)\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.min_along_batch","title":"redcat.ba.BatchedArray.min_along_batch","text":"<pre><code>min_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.min_along_batch()\narray([1, 4, 2])\n&gt;&gt;&gt; batch.min_along_batch(keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.min_along_batch()\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mul","title":"redcat.ba.BatchedArray.mul","text":"<pre><code>mul(other: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Multiplies the <code>self</code> batch by the input <code>`other</code>.</p> <p>Similar to <code>out = self * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to multiply.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the multiplication of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.mul(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.mul_","title":"redcat.ba.BatchedArray.mul_","text":"<pre><code>mul_(other: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Multiplies the <code>self</code> batch by the input <code>`other</code>.</p> <p>Similar to <code>self *= other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to multiply.</p> required <p>Returns:</p> Type Description <code>None</code> <p>A new batch containing the multiplication of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.mul_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[2., 2., 2.],\n       [2., 2., 2.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmax","title":"redcat.ba.BatchedArray.nanargmax","text":"<pre><code>nanargmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along an axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along an axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmax()\n5\n&gt;&gt;&gt; batch.nanargmax(keepdims=True)\narray([[5]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmax_along_batch","title":"redcat.ba.BatchedArray.nanargmax_along_batch","text":"<pre><code>nanargmax_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmax_along_batch()\narray([1, 1, 1])\n&gt;&gt;&gt; batch.nanargmax_along_batch(keepdims=True)\narray([[1, 1, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmin","title":"redcat.ba.BatchedArray.nanargmin","text":"<pre><code>nanargmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along an axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along an axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmin()\n0\n&gt;&gt;&gt; batch.nanargmin(keepdims=True)\narray([[0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanargmin_along_batch","title":"redcat.ba.BatchedArray.nanargmin_along_batch","text":"<pre><code>nanargmin_along_batch(\n    out: ndarray | None = None, *, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <p>By default, the index is into the flattened array, otherwise along the specified axis.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanargmin_along_batch()\narray([0, 1, 0])\n&gt;&gt;&gt; batch.nanargmin_along_batch(keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumprod","title":"redcat.ba.BatchedArray.nancumprod","text":"<pre><code>nancumprod(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>nancumprod(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>nancumprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumprod(axis=0)\narray([[ 1.,  1.,  2.],\n       [ 3.,  4., 10.]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nancumprod(axis=1)\narray([[ 1.,  1.,  2.],\n       [ 3., 12., 60.]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumprod_along_batch","title":"redcat.ba.BatchedArray.nancumprod_along_batch","text":"<pre><code>nancumprod_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumprod_along_batch()\narray([[ 1.,  1.,  2.],\n       [ 3.,  4., 10.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumsum","title":"redcat.ba.BatchedArray.nancumsum","text":"<pre><code>nancumsum(\n    axis: None = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; ndarray\n</code></pre><pre><code>nancumsum(\n    axis: SupportsIndex = ...,\n    dtype: DTypeLike = ...,\n    out: ndarray | None = ...,\n) -&gt; Self\n</code></pre> <pre><code>nancumsum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the cumulative sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The cumulative sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumsum(axis=0)\narray([[1., 0., 2.],\n       [4., 4., 7.]], batch_axis=0)\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nancumsum(axis=1)\narray([[ 1.,  1.,  3.],\n       [ 3.,  7., 12.]], batch_axis=1)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nancumsum_along_batch","title":"redcat.ba.BatchedArray.nancumsum_along_batch","text":"<pre><code>nancumsum_along_batch(dtype: DTypeLike = None) -&gt; Self\n</code></pre> <p>Return the cumulative sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The cumulative sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nancumsum_along_batch()\narray([[1., 0., 2.],\n       [4., 4., 7.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmax","title":"redcat.ba.BatchedArray.nanmax","text":"<pre><code>nanmax(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmax()\n5.0\n&gt;&gt;&gt; batch.nanmax(axis=0)\narray([3., 4., 5.])\n&gt;&gt;&gt; batch.nanmax(axis=0, keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmax(axis=1)\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmax_along_batch","title":"redcat.ba.BatchedArray.nanmax_along_batch","text":"<pre><code>nanmax_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmax_along_batch()\narray([3., 4., 5.])\n&gt;&gt;&gt; batch.nanmax_along_batch(keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmax_along_batch()\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmean","title":"redcat.ba.BatchedArray.nanmean","text":"<pre><code>nanmean(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmean()\n3.0\n&gt;&gt;&gt; batch.nanmean(axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmean(axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch.nanmean(axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmean_along_batch","title":"redcat.ba.BatchedArray.nanmean_along_batch","text":"<pre><code>nanmean_along_batch(\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmean_along_batch()\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmean_along_batch(keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmean_along_batch()\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmedian","title":"redcat.ba.BatchedArray.nanmedian","text":"<pre><code>nanmedian(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative sum is computed. By default, the input is flattened.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmedian()\n3.0\n&gt;&gt;&gt; batch.nanmedian(axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmedian(axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch.nanmedian(axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmedian_along_batch","title":"redcat.ba.BatchedArray.nanmedian_along_batch","text":"<pre><code>nanmedian_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; Self | ndarray\n</code></pre> <p>Return the median along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The median along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmedian_along_batch()\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; batch.nanmedian_along_batch(keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmedian_along_batch()\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmin","title":"redcat.ba.BatchedArray.nanmin","text":"<pre><code>nanmin(\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmin()\n2.0\n&gt;&gt;&gt; batch.nanmin(axis=0)\narray([3., 4., 2.])\n&gt;&gt;&gt; batch.nanmin(axis=0, keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmin(axis=1)\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanmin_along_batch","title":"redcat.ba.BatchedArray.nanmin_along_batch","text":"<pre><code>nanmin_along_batch(\n    out: ndarray | None = None, keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanmin_along_batch()\narray([3., 4., 2.])\n&gt;&gt;&gt; batch.nanmin_along_batch(keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanmin_along_batch()\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanprod","title":"redcat.ba.BatchedArray.nanprod","text":"<pre><code>nanprod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanprod(axis=0)\narray([ 3., 4., 10.])\n&gt;&gt;&gt; batch.nanprod(axis=0, keepdims=True)\narray([[ 3., 4., 10.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nanprod(axis=1)\narray([ 2., 60.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nanprod_along_batch","title":"redcat.ba.BatchedArray.nanprod_along_batch","text":"<pre><code>nanprod_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nanprod_along_batch()\narray([ 3., 4., 10.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nansum","title":"redcat.ba.BatchedArray.nansum","text":"<pre><code>nansum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nansum(axis=0)\narray([4., 4., 7.])\n&gt;&gt;&gt; batch.nansum(axis=0, keepdims=True)\narray([[4., 4., 7.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.nansum(axis=1)\narray([ 3., 12.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.nansum_along_batch","title":"redcat.ba.BatchedArray.nansum_along_batch","text":"<pre><code>nansum_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.nansum_along_batch()\narray([4., 4., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.neg","title":"redcat.ba.BatchedArray.neg","text":"<pre><code>neg() -&gt; Self\n</code></pre> <p>Return a new batch with the negative of the elements.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with the negative of the elements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.neg()\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.ones_like","title":"redcat.ba.BatchedArray.ones_like","text":"<pre><code>ones_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>1</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.zeros((2, 3))\n&gt;&gt;&gt; array.ones_like()\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; array.ones_like(batch_size=5)\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.permute_along_axis","title":"redcat.ba.BatchedArray.permute_along_axis","text":"<pre><code>permute_along_axis(\n    permutation: ndarray | Sequence[int], axis: int\n) -&gt; Self\n</code></pre> <p>Permute the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>ndarray | Sequence[int]</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis where the permutation is computed.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with permuted data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.permute_along_axis([2, 1, 3, 0, 4], axis=0)\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.permute_along_axis_","title":"redcat.ba.BatchedArray.permute_along_axis_","text":"<pre><code>permute_along_axis_(\n    permutation: ndarray | Sequence[int], axis: int\n) -&gt; None\n</code></pre> <p>Permutes the data/batch along a given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>permutation</code> <code>ndarray | Sequence[int]</code> <p>Specifies the permutation to use on the data. The dimension of the permutation input should be compatible with the shape of the data.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis where the permutation is computed.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.permute_along_axis_([2, 1, 3, 0, 4], axis=0)\n&gt;&gt;&gt; batch\narray([[4, 5],\n       [2, 3],\n       [6, 7],\n       [0, 1],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.prod","title":"redcat.ba.BatchedArray.prod","text":"<pre><code>prod(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the product of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The product of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.prod(axis=0)\narray([ 3, 24, 10])\n&gt;&gt;&gt; batch.prod(axis=0, keepdims=True)\narray([[ 3, 24, 10]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.prod(axis=1)\narray([12, 60])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.prod_along_batch","title":"redcat.ba.BatchedArray.prod_along_batch","text":"<pre><code>prod_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.prod_along_batch()\narray([ 3, 24, 10])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.select","title":"redcat.ba.BatchedArray.select","text":"<pre><code>select(index: int, axis: int) -&gt; ndarray\n</code></pre> <p>Select the data along the given axis at the given index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Specifies the index to select.</p> required <code>axis</code> <code>int</code> <p>Specifies the index axis.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The batch sliced along the given axis at the given index.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.select(index=2, axis=0)\narray([4, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shuffle_along_axis","title":"redcat.ba.BatchedArray.shuffle_along_axis","text":"<pre><code>shuffle_along_axis(\n    axis: int, rng: Generator | None = None\n) -&gt; Self\n</code></pre> <p>Shuffle the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the shuffle axis.</p> required <code>rng</code> <code>Generator | None</code> <p>Specifies the pseudorandom number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch with shuffled data along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.shuffle_along_axis(axis=0)\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.shuffle_along_axis_","title":"redcat.ba.BatchedArray.shuffle_along_axis_","text":"<pre><code>shuffle_along_axis_(\n    axis: int, rng: Generator | None = None\n) -&gt; None\n</code></pre> <p>Shuffle the data/batch along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the shuffle axis.</p> required <code>rng</code> <code>Generator | None</code> <p>Specifies the pseudorandom number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>A new batch with shuffled data along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.shuffle_along_axis_(axis=0)\n&gt;&gt;&gt; batch\narray([[...]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.slice_along_axis","title":"redcat.ba.BatchedArray.slice_along_axis","text":"<pre><code>slice_along_axis(\n    axis: int = 0,\n    start: int = 0,\n    stop: int | None = None,\n    step: int = 1,\n) -&gt; Self\n</code></pre> <p>Slice the batch in a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>int</code> <p>Specifies the axis along which to slice the array.</p> <code>0</code> <code>start</code> <code>int</code> <p>Specifies the index where the slicing starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A slice of the current batch along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.slice_along_axis(start=2)\narray([[4, 5],\n       [6, 7],\n       [8, 9]], batch_axis=0)\n&gt;&gt;&gt; batch.slice_along_axis(stop=3)\narray([[0, 1],\n       [2, 3],\n       [4, 5]], batch_axis=0)\n&gt;&gt;&gt; batch.slice_along_axis(step=2)\narray([[0, 1],\n       [4, 5],\n       [8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sort","title":"redcat.ba.BatchedArray.sort","text":"<pre><code>sort(\n    axis: SupportsIndex | None = -1,\n    kind: SortKind | None = None,\n) -&gt; None\n</code></pre> <p>Sort an array in-place.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which to sort.</p> <code>-1</code> <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sort()\n&gt;&gt;&gt; batch\narray([[1, 2, 6],\n       [3, 4, 5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sort_along_batch","title":"redcat.ba.BatchedArray.sort_along_batch","text":"<pre><code>sort_along_batch(kind: str | None = None) -&gt; None\n</code></pre> <p>Sort an array in-place along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str | None</code> <p>Sorting algorithm. The default is <code>quicksort</code>. Note that both <code>stable</code> and <code>mergesort</code> use timsort under the covers and, in general, the actual implementation will vary with datatype. The <code>mergesort</code> option is retained for backwards compatibility.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sort_along_batch()\n&gt;&gt;&gt; batch\narray([[1, 4, 2],\n       [3, 6, 5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.split_along_axis","title":"redcat.ba.BatchedArray.split_along_axis","text":"<pre><code>split_along_axis(\n    split_size_or_sections: int | Sequence[int],\n    axis: int = 0,\n) -&gt; tuple[Self, ...]\n</code></pre> <p>Split the batch into chunks along a given axis.</p> Notes <p>This function has a slightly different behavior as     <code>numpy.split</code>.</p> <p>Parameters:</p> Name Type Description Default <code>split_size_or_sections</code> <code>int | Sequence[int]</code> <p>Specifies the size of a single chunk or list of sizes for each chunk.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis along which to split the array.</p> <code>0</code> <p>Returns:</p> Type Description <code>tuple[Self, ...]</code> <p>The batch split into chunks along the given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; batch.split_along_axis(2, axis=0)\n(array([[0, 1], [2, 3]], batch_axis=0),\n array([[4, 5], [6, 7]], batch_axis=0),\n array([[8, 9]], batch_axis=0))\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sub","title":"redcat.ba.BatchedArray.sub","text":"<pre><code>sub(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; Self\n</code></pre> <p>Subtracts the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>out = self - alpha * other</code></p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to subtract.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to substract.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new batch containing the diffence of the two batches.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.sub(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sub_","title":"redcat.ba.BatchedArray.sub_","text":"<pre><code>sub_(\n    other: BatchedArray | ndarray | float, alpha: float = 1\n) -&gt; None\n</code></pre> <p>Subtracts the input <code>other</code>, scaled by <code>alpha</code>, to the <code>self</code> batch.</p> <p>Similar to <code>self -= alpha * other</code> (in-place)</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the value to subtract.</p> required <code>alpha</code> <code>float</code> <p>Specifies the scale of the batch to substract.</p> <code>1</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.sub_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[-1., -1., -1.],\n       [-1., -1., -1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sum","title":"redcat.ba.BatchedArray.sum","text":"<pre><code>sum(\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; Self | ndarray\n</code></pre> <p>Return the sum of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self | ndarray</code> <p>The sum of elements along a given axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sum(axis=0)\narray([ 4, 10, 7])\n&gt;&gt;&gt; batch.sum(axis=0, keepdims=True)\narray([[ 4, 10, 7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; batch.sum(axis=1)\narray([ 9, 12])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.sum_along_batch","title":"redcat.ba.BatchedArray.sum_along_batch","text":"<pre><code>sum_along_batch(\n    dtype: DTypeLike = None, keepdims: bool = False\n) -&gt; Self\n</code></pre> <p>Return the sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; batch.sum_along_batch()\narray([ 4, 10, 7])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.truediv","title":"redcat.ba.BatchedArray.truediv","text":"<pre><code>truediv(divisor: BatchedArray | ndarray | float) -&gt; Self\n</code></pre> <p>Return the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The division of the inputs.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; out = batch.truediv(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; out\narray([[0.5, 0.5, 0.5],\n       [0.5, 0.5, 0.5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.truediv_","title":"redcat.ba.BatchedArray.truediv_","text":"<pre><code>truediv_(divisor: BatchedArray | ndarray | float) -&gt; None\n</code></pre> <p>Return the division of the inputs.</p> <p>The current batch is the dividend/numerator.</p> <p>Parameters:</p> Name Type Description Default <code>divisor</code> <code>BatchedArray | ndarray | float</code> <p>Specifies the divisor/denominator.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch.truediv_(ba.full((2, 3), 2.0))\n&gt;&gt;&gt; batch\narray([[0.5, 0.5, 0.5],\n       [0.5, 0.5, 0.5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.BatchedArray.zeros_like","title":"redcat.ba.BatchedArray.zeros_like","text":"<pre><code>zeros_like(\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; Self\n</code></pre> <p>Return an array filled with the scalar value <code>0</code>, with the same shape as the current array.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if <code>self</code> is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of <code>self</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>self</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order=<code>K</code> and thenumber of dimensions is unchanged, will try to keep order, otherwise, order=<code>C</code> is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An array filled with the scalar value <code>0</code>, with the same shape as the current array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; array.zeros_like()\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n&gt;&gt;&gt; array.zeros_like(batch_size=5)\narray([[0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.argmax","title":"redcat.ba.argmax","text":"<pre><code>argmax(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>See <code>numpy.argmax</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.argmax_along_batch","title":"redcat.ba.argmax_along_batch","text":"<pre><code>argmax_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.argmax_along_batch(batch)\narray([1, 0, 1])\n&gt;&gt;&gt; ba.argmax_along_batch(batch, keepdims=True)\narray([[1, 0, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.argmin","title":"redcat.ba.argmin","text":"<pre><code>argmin(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>See <code>numpy.argmin</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.argmin_along_batch","title":"redcat.ba.argmin_along_batch","text":"<pre><code>argmin_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.argmin_along_batch(batch)\narray([0, 1, 0])\n&gt;&gt;&gt; ba.argmin_along_batch(batch, keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.argsort","title":"redcat.ba.argsort","text":"<pre><code>argsort(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = -1,\n    kind: SortKind | None = None,\n) -&gt; TBatchedArray\n</code></pre> <p>See <code>numpy.argsort</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.argsort_along_batch","title":"redcat.ba.argsort_along_batch","text":"<pre><code>argsort_along_batch(\n    a: TBatchedArray, kind: SortKind | None = None\n) -&gt; TBatchedArray\n</code></pre> <p>Return the indices that would sort an array.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is 'quicksort'. Note that both 'stable' and 'mergesort' use timsort under the covers and, in general, the actual implementation will vary with datatype. The 'mergesort' option is retained for backwards compatibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The indices that would sort an array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.argsort_along_batch(batch)\narray([[0, 1, 0],\n       [1, 0, 1]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.array","title":"redcat.ba.array","text":"<pre><code>array(\n    data: ArrayLike | Sequence,\n    dtype: DTypeLike = None,\n    *,\n    batch_axis: int = 0,\n    **kwargs: Any\n) -&gt; BatchedArray\n</code></pre> <p>Create an array.</p> <p>Equivalent of <code>numpy.array</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ArrayLike | Sequence</code> <p>An array, any object exposing the array interface, an object whose <code>__array__</code> method returns an array, or any (nested) sequence. If object is a scalar, a 0-dimensional array containing object is returned.</p> required <code>dtype</code> <code>DTypeLike</code> <p>The desired data-type for the array. If not given, NumPy will try to use a default dtype that can represent the values (by applying promotion rules when necessary.)</p> <code>None</code> <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>See the documentation of <code>numpy.array</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BatchedArray</code> <p>An array object satisfying the specified requirements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.array(np.arange(10).reshape(2, 5))\n&gt;&gt;&gt; batch\narray([[0, 1, 2, 3, 4],\n       [5, 6, 7, 8, 9]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.check_data_and_axis","title":"redcat.ba.check_data_and_axis","text":"<pre><code>check_data_and_axis(data: ndarray, batch_axis: int) -&gt; None\n</code></pre> <p>Check if the array <code>data</code> and <code>batch_axis</code> are correct.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Specifies the array in the batch.</p> required <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the input is incorrect.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.ba import check_data_and_axis\n&gt;&gt;&gt; check_data_and_axis(np.ones((2, 3)), batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.check_same_batch_axis","title":"redcat.ba.check_same_batch_axis","text":"<pre><code>check_same_batch_axis(axes: set[int]) -&gt; None\n</code></pre> <p>Check the batch axes are the same.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>set[int]</code> <p>Specifies the batch axes to check.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if there are more than one batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.ba import check_same_batch_axis\n&gt;&gt;&gt; check_same_batch_axis({0})\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.concatenate","title":"redcat.ba.concatenate","text":"<pre><code>concatenate(\n    arrays: Sequence[TBatchedArray], axis: int | None = 0\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>See <code>numpy.concatenate</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.concatenate_along_batch","title":"redcat.ba.concatenate_along_batch","text":"<pre><code>concatenate_along_batch(\n    arrays: Sequence[TBatchedArray],\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Join a sequence of arrays along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Sequence[TBatchedArray]</code> <p>The arrays must have the same shape, except in the dimension corresponding to axis.</p> required <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The concatenated array.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the batch axes are different.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; arrays = [\n...     ba.array([[0, 1, 2], [4, 5, 6]]),\n...     ba.array([[10, 11, 12], [13, 14, 15]]),\n... ]\n&gt;&gt;&gt; out = ba.concatenate_along_batch(arrays)\n&gt;&gt;&gt; out\narray([[ 0,  1,  2],\n       [ 4,  5,  6],\n       [10, 11, 12],\n       [13, 14, 15]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.cumprod","title":"redcat.ba.cumprod","text":"<pre><code>cumprod(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>See <code>numpy.cumprod</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.cumprod_along_batch","title":"redcat.ba.cumprod_along_batch","text":"<pre><code>cumprod_along_batch(\n    a: TBatchedArray, dtype: DTypeLike = None\n) -&gt; TBatchedArray\n</code></pre> <p>Return the cumulative product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The cumulative product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; ba.cumprod_along_batch(batch)\narray([[  0,   1],\n       [  0,   3],\n       [  0,  15],\n       [  0, 105],\n       [  0, 945]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.cumsum","title":"redcat.ba.cumsum","text":"<pre><code>cumsum(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>See <code>numpy.cumsum</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.cumsum_along_batch","title":"redcat.ba.cumsum_along_batch","text":"<pre><code>cumsum_along_batch(\n    a: TBatchedArray, dtype: DTypeLike = None\n) -&gt; TBatchedArray\n</code></pre> <p>Return the cumulative sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The cumulative sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.arange(10).reshape(5, 2))\n&gt;&gt;&gt; ba.cumsum_along_batch(batch)\narray([[ 0,  1],\n       [ 2,  4],\n       [ 6,  9],\n       [12, 16],\n       [20, 25]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.diff","title":"redcat.ba.diff","text":"<pre><code>diff(\n    a: TBatchedArray,\n    n: int = 1,\n    axis: SupportsIndex = -1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the given axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>axis</code> <code>SupportsIndex</code> <p>The axis along which the difference is taken, default is the last axis.</p> <code>-1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the current array along axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; ba.diff(batch, n=1, axis=0)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; ba.diff(batch, axis=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.diff_along_batch","title":"redcat.ba.diff_along_batch","text":"<pre><code>diff_along_batch(\n    a: TBatchedArray,\n    n: int = 1,\n    prepend: ArrayLike = _NoValue,\n    append: ArrayLike = _NoValue,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Calculate the n-th discrete difference along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>n</code> <code>int</code> <p>The number of times values are differenced. If zero, the input is returned as-is.</p> <code>1</code> <code>prepend</code> <code>ArrayLike</code> <p>Values to prepend to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <code>append</code> <code>ArrayLike</code> <p>Values to append to the array along the batch axis prior to performing the difference. Scalar values are expanded to arrays with length 1 in the direction of axis and the shape of the input array in along all other axes. Otherwise the dimension and shape must match the current array except along axis.</p> <code>_NoValue</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The n-th differences. The shape of the output is the same as the current array except along the batch axis where the dimension is smaller by <code>n</code>. The type of the output is the same as the type of the difference between any two elements of the array. This is the same as the type of the current array in most cases.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = BatchedArray(np.array([[6, 3], [6, 2], [7, 9], [0, 0], [6, 7]]))\n&gt;&gt;&gt; ba.diff_along_batch(batch, n=1)\narray([[ 0, -1],\n       [ 1,  7],\n       [-7, -9],\n       [ 6,  7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[9, 3, 7, 4, 0], [6, 6, 2, 3, 3]]), batch_axis=1)\n&gt;&gt;&gt; ba.diff_along_batch(batch, n=1)\narray([[-6,  4, -3, -4], [ 0, -4,  1,  0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.empty","title":"redcat.ba.empty","text":"<pre><code>empty(\n    shape: int | Sequence[int],\n    dtype: DTypeLike = None,\n    order: str = \"C\",\n    *,\n    batch_axis: int = 0,\n    **kwargs: Any\n) -&gt; BatchedArray\n</code></pre> <p>Return a new array of given shape and type, without initializing entries.</p> <p>Equivalent of <code>numpy.empty</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int | Sequence[int]</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>dtype</code> <code>DTypeLike</code> <p>The desired data-type for the array.</p> <code>None</code> <code>order</code> <code>str</code> <p>Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.</p> <code>'C'</code> <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>See the documentation of <code>numpy.empty</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BatchedArray</code> <p>An array object satisfying the specified requirements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.empty((2, 3))\n&gt;&gt;&gt; batch\narray([...], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.empty_like","title":"redcat.ba.empty_like","text":"<pre><code>empty_like(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; TBatchedArray\n</code></pre> <p>Return an array of zeros with the same shape and type as a given array.</p> <p>Equivalent of <code>numpy.empty_like</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The shape and data-type of a define these same attributes of the returned array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. 'C' means C-order, 'F' means F-order, 'A' means 'F' if <code>a</code> is Fortran contiguous, 'C' otherwise. 'K' means match the layout of <code>a</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>a</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order='K' and the number of dimensions is unchanged, will try to keep order, otherwise, order='C' is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>Array of zeros with the same shape and type as <code>a</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 3))\n&gt;&gt;&gt; ba.empty_like(array).shape\n(2, 3)\n&gt;&gt;&gt; ba.empty_like(array, batch_size=5).shape\n(5, 3)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.full","title":"redcat.ba.full","text":"<pre><code>full(\n    shape: int | Sequence[int],\n    fill_value: float | ArrayLike,\n    dtype: DTypeLike = None,\n    order: str = \"C\",\n    *,\n    batch_axis: int = 0,\n    **kwargs: Any\n) -&gt; BatchedArray\n</code></pre> <p>Return a new array of given shape and type, filled with <code>fill_value</code>.</p> <p>Equivalent of <code>numpy.full</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int | Sequence[int]</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>fill_value</code> <code>float | ArrayLike</code> <p>Specifies the fill value.</p> required <code>dtype</code> <code>DTypeLike</code> <p>The desired data-type for the array.</p> <code>None</code> <code>order</code> <code>str</code> <p>Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.</p> <code>'C'</code> <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>See the documentation of <code>numpy.full</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BatchedArray</code> <p>An array object satisfying the specified requirements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.full((2, 3), fill_value=42)\n&gt;&gt;&gt; batch\narray([[42, 42, 42],\n       [42, 42, 42]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.full_like","title":"redcat.ba.full_like","text":"<pre><code>full_like(\n    a: TBatchedArray,\n    fill_value: ArrayLike,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; TBatchedArray\n</code></pre> <p>Return an array of ones with the same shape and type as a given array.</p> <p>Equivalent of <code>numpy.full_like</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The shape and data-type of a define these same attributes of the returned array.</p> required <code>fill_value</code> <code>ArrayLike</code> <p>Specifies the fill value.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. 'C' means C-order, 'F' means F-order, 'A' means 'F' if <code>a</code> is Fortran contiguous, 'C' otherwise. 'K' means match the layout of <code>a</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>a</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order='K' and the number of dimensions is unchanged, will try to keep order, otherwise, order='C' is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>Array of ones with the same shape and type as <code>a</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.zeros((2, 5))\n&gt;&gt;&gt; ba.full_like(array, fill_value=2)\narray([[2., 2., 2., 2., 2.],\n       [2., 2., 2., 2., 2.]], batch_axis=0)\n&gt;&gt;&gt; ba.full_like(array, fill_value=42, batch_size=5)\narray([[42., 42., 42., 42., 42.],\n       [42., 42., 42., 42., 42.],\n       [42., 42., 42., 42., 42.],\n       [42., 42., 42., 42., 42.],\n       [42., 42., 42., 42., 42.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.get_batch_axes","title":"redcat.ba.get_batch_axes","text":"<pre><code>get_batch_axes(\n    args: Iterable[Any],\n    kwargs: Mapping[str, Any] | None = None,\n) -&gt; set[int]\n</code></pre> <p>Return batch axes from the inputs.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Iterable[Any]</code> <p>Variable length argument list.</p> required <code>kwargs</code> <code>Mapping[str, Any] | None</code> <p>Arbitrary keyword arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>set[int]</code> <p>The batch axes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; from redcat.ba import get_batch_axes\n&gt;&gt;&gt; get_batch_axes(\n...     args=(ba.ones((2, 3)), ba.ones((2, 6))),\n...     kwargs={\"batch\": ba.ones((2, 4))},\n... )\n{0}\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.max","title":"redcat.ba.max","text":"<pre><code>max(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.max(batch)\n6\n&gt;&gt;&gt; ba.max(batch, axis=0)\narray([3, 6, 5])\n&gt;&gt;&gt; ba.max(batch, axis=0, keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.max(batch, axis=1)\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.max_along_batch","title":"redcat.ba.max_along_batch","text":"<pre><code>max_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.max_along_batch(batch)\narray([3, 6, 5])\n&gt;&gt;&gt; ba.max_along_batch(batch, keepdims=True)\narray([[3, 6, 5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.max_along_batch(batch)\narray([6, 5])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.mean","title":"redcat.ba.mean","text":"<pre><code>mean(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The arithmetic mean along the specified axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.mean(batch)\n3.5\n&gt;&gt;&gt; ba.mean(batch, axis=0)\narray([2. , 5. , 3.5])\n&gt;&gt;&gt; ba.mean(batch, axis=0, keepdims=True)\narray([[2. , 5. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.mean(batch, axis=1)\narray([3., 4.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.mean_along_batch","title":"redcat.ba.mean_along_batch","text":"<pre><code>mean_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return tne arithmetic mean along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The arithmetic mean along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.mean_along_batch(batch)\narray([2. , 5. , 3.5])\n&gt;&gt;&gt; ba.mean_along_batch(batch, keepdims=True)\narray([[2. , 5. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.mean_along_batch(batch)\narray([3., 4.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.median","title":"redcat.ba.median","text":"<pre><code>median(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the median along the specified axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median along the specified axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.mean(batch)\n3.5\n&gt;&gt;&gt; ba.mean(batch, axis=0)\narray([2. , 5. , 3.5])\n&gt;&gt;&gt; ba.mean(batch, axis=0, keepdims=True)\narray([[2. , 5. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.mean(batch, axis=1)\narray([3., 4.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.median_along_batch","title":"redcat.ba.median_along_batch","text":"<pre><code>median_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return tne median along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median along the specified axis. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input. If out is specified, that array is returned instead.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.mean_along_batch(batch)\narray([2. , 5. , 3.5])\n&gt;&gt;&gt; ba.mean_along_batch(batch, keepdims=True)\narray([[2. , 5. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.mean_along_batch(batch)\narray([3., 4.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.min","title":"redcat.ba.min","text":"<pre><code>min(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.min(batch)\n1\n&gt;&gt;&gt; ba.min(batch, axis=0)\narray([1, 4, 2])\n&gt;&gt;&gt; ba.min(batch, axis=0, keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.min(batch, axis=1)\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.min_along_batch","title":"redcat.ba.min_along_batch","text":"<pre><code>min_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.min_along_batch(batch)\narray([1, 4, 2])\n&gt;&gt;&gt; ba.min_along_batch(batch, keepdims=True)\narray([[1, 4, 2]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.min_along_batch(batch)\narray([1, 3])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanargmax","title":"redcat.ba.nanargmax","text":"<pre><code>nanargmax(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>See <code>numpy.nanargmax</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.nanargmax_along_batch","title":"redcat.ba.nanargmax_along_batch","text":"<pre><code>nanargmax_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the maximum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanargmax_along_batch(batch)\narray([1, 1, 1])\n&gt;&gt;&gt; ba.nanargmax_along_batch(batch, keepdims=True)\narray([[1, 1, 1]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanargmin","title":"redcat.ba.nanargmin","text":"<pre><code>nanargmin(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>See <code>numpy.nanargmin</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.nanargmin_along_batch","title":"redcat.ba.nanargmin_along_batch","text":"<pre><code>nanargmin_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    *,\n    keepdims: bool = False\n) -&gt; ndarray\n</code></pre> <p>Return the indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>If provided, the result will be inserted into this array. It should be of the appropriate shape and dtype.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The indices of the minimum values along the batch axis ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanargmin_along_batch(batch)\narray([0, 1, 0])\n&gt;&gt;&gt; ba.nanargmin_along_batch(batch, keepdims=True)\narray([[0, 1, 0]])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nancumprod","title":"redcat.ba.nancumprod","text":"<pre><code>nancumprod(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>See <code>numpy.nancumprod</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.nancumprod_along_batch","title":"redcat.ba.nancumprod_along_batch","text":"<pre><code>nancumprod_along_batch(\n    a: TBatchedArray, dtype: DTypeLike = None\n) -&gt; TBatchedArray\n</code></pre> <p>Return the cumulative product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The cumulative product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nancumprod_along_batch(batch)\narray([[ 1.,  1.,  2.],\n       [ 3.,  4., 10.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nancumsum","title":"redcat.ba.nancumsum","text":"<pre><code>nancumsum(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>See <code>numpy.nancumsum</code> documentation.</p>"},{"location":"refs/batchedarray/#redcat.ba.nancumsum_along_batch","title":"redcat.ba.nancumsum_along_batch","text":"<pre><code>nancumsum_along_batch(\n    a: TBatchedArray, dtype: DTypeLike = None\n) -&gt; TBatchedArray\n</code></pre> <p>Return the cumulative sum of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The cumulative sum of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nancumsum_along_batch(batch)\narray([[1., 0., 2.],\n       [4., 4., 7.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmax","title":"redcat.ba.nanmax","text":"<pre><code>nanmax(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum of an array or maximum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmax(batch)\n5.0\n&gt;&gt;&gt; ba.nanmax(batch, axis=0)\narray([3., 4., 5.])\n&gt;&gt;&gt; ba.nanmax(batch, axis=0, keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmax(batch, axis=1)\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmax_along_batch","title":"redcat.ba.nanmax_along_batch","text":"<pre><code>nanmax_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the maximum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The maximum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmax_along_batch(batch)\narray([3., 4., 5.])\n&gt;&gt;&gt; ba.nanmax_along_batch(batch, keepdims=True)\narray([[3., 4., 5.]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmax_along_batch(batch)\narray([2., 5.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmean","title":"redcat.ba.nanmean","text":"<pre><code>nanmean(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The arithmetic mean along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmean(batch)\n3.0\n&gt;&gt;&gt; ba.nanmean(batch, axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; ba.nanmean(batch, axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; ba.nanmean(batch, axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmean_along_batch","title":"redcat.ba.nanmean_along_batch","text":"<pre><code>nanmean_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return tne arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The arithmetic mean along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmean_along_batch(batch)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; ba.nanmean_along_batch(batch, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmean_along_batch(batch)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmedian","title":"redcat.ba.nanmedian","text":"<pre><code>nanmedian(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the median along the specified axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median along the specified axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmedian(batch)\n3.0\n&gt;&gt;&gt; ba.nanmedian(batch, axis=0)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; ba.nanmedian(batch, axis=0, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; ba.nanmedian(batch, axis=1)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmedian_along_batch","title":"redcat.ba.nanmedian_along_batch","text":"<pre><code>nanmedian_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return tne median along the batch axis, ignoring NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The median along the batch axis, ignoring NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmedian_along_batch(batch)\narray([2. , 4. , 3.5])\n&gt;&gt;&gt; ba.nanmedian_along_batch(batch, keepdims=True)\narray([[2. , 4. , 3.5]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmedian_along_batch(batch)\narray([1.5, 4. ])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmin","title":"redcat.ba.nanmin","text":"<pre><code>nanmin(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis or axes along which to operate. By default, flattened input is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum of an array or minimum along an axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmin(batch)\n2.0\n&gt;&gt;&gt; ba.nanmin(batch, axis=0)\narray([3., 4., 2.])\n&gt;&gt;&gt; ba.nanmin(batch, axis=0, keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmin(batch, axis=1)\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanmin_along_batch","title":"redcat.ba.nanmin_along_batch","text":"<pre><code>nanmin_along_batch(\n    a: TBatchedArray,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; ndarray\n</code></pre> <p>Return the minimum along the batch axis, ignoring any NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The minimum along the batch axis, ignoring any NaNs.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanmin_along_batch(batch)\narray([3., 4., 2.])\n&gt;&gt;&gt; ba.nanmin_along_batch(batch, keepdims=True)\narray([[3., 4., 2.]])\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[np.nan, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanmin_along_batch(batch)\narray([2., 3.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanprod","title":"redcat.ba.nanprod","text":"<pre><code>nanprod(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Return the product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The product of elements along a given axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanprod(batch, axis=0)\narray([ 3., 4., 10.])\n&gt;&gt;&gt; ba.nanprod(batch, axis=0, keepdims=True)\narray([[ 3., 4., 10.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nanprod(batch, axis=1)\narray([ 2., 60.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nanprod_along_batch","title":"redcat.ba.nanprod_along_batch","text":"<pre><code>nanprod_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray\n</code></pre> <p>Return the product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The product of elements along the batch axis treating Not a Numbers (NaNs) as one.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nanprod_along_batch(batch)\narray([ 3., 4., 10.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nansum","title":"redcat.ba.nansum","text":"<pre><code>nansum(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Return the sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nansum(batch, axis=0)\narray([4., 4., 7.])\n&gt;&gt;&gt; ba.nansum(batch, axis=0, keepdims=True)\narray([[4., 4., 7.]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.nansum(batch, axis=1)\narray([ 3., 12.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.nansum_along_batch","title":"redcat.ba.nansum_along_batch","text":"<pre><code>nansum_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray\n</code></pre> <p>Return the sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, np.nan, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.nansum_along_batch(batch)\narray([4., 4., 7.])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.ones","title":"redcat.ba.ones","text":"<pre><code>ones(\n    shape: int | Sequence[int],\n    dtype: DTypeLike = None,\n    order: str = \"C\",\n    *,\n    batch_axis: int = 0,\n    **kwargs: Any\n) -&gt; BatchedArray\n</code></pre> <p>Return a new array of given shape and type, filled with ones.</p> <p>Equivalent of <code>numpy.ones</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int | Sequence[int]</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>dtype</code> <code>DTypeLike</code> <p>The desired data-type for the array.</p> <code>None</code> <code>order</code> <code>str</code> <p>Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.</p> <code>'C'</code> <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>See the documentation of <code>numpy.ones</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BatchedArray</code> <p>An array object satisfying the specified requirements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.ones((2, 3))\n&gt;&gt;&gt; batch\narray([[1., 1., 1.],\n       [1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.ones_like","title":"redcat.ba.ones_like","text":"<pre><code>ones_like(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; TBatchedArray\n</code></pre> <p>Return an array of ones with the same shape and type as a given array.</p> <p>Equivalent of <code>numpy.ones_like</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The shape and data-type of a define these same attributes of the returned array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. 'C' means C-order, 'F' means F-order, 'A' means 'F' if <code>a</code> is Fortran contiguous, 'C' otherwise. 'K' means match the layout of <code>a</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>a</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order='K' and the number of dimensions is unchanged, will try to keep order, otherwise, order='C' is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>Array of ones with the same shape and type as <code>a</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.zeros((2, 5))\n&gt;&gt;&gt; ba.ones_like(array)\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]], batch_axis=0)\n&gt;&gt;&gt; ba.ones_like(array, batch_size=5)\narray([[1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.prod","title":"redcat.ba.prod","text":"<pre><code>prod(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Return the product of elements along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The product of elements along a given axis treating.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.prod(batch, axis=0)\narray([ 3, 24, 10])\n&gt;&gt;&gt; ba.prod(batch, axis=0, keepdims=True)\narray([[ 3, 24, 10]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.prod(batch, axis=1)\narray([12, 60])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.prod_along_batch","title":"redcat.ba.prod_along_batch","text":"<pre><code>prod_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray\n</code></pre> <p>Return the product of elements along the batch axis.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are multiplied. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The product of elements along the batch axis.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.prod_along_batch(batch)\narray([ 3, 24, 10])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.sort_along_batch","title":"redcat.ba.sort_along_batch","text":"<pre><code>sort_along_batch(\n    a: TBatchedArray, kind: SortKind | None = None\n) -&gt; TBatchedArray\n</code></pre> <p>Sort an array along the batch dimension.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>kind</code> <code>SortKind | None</code> <p>Sorting algorithm. The default is 'quicksort'. Note that both 'stable' and 'mergesort' use timsort under the covers and, in general, the actual implementation will vary with datatype. The 'mergesort' option is retained for backwards compatibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>A sorted copy of an array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.sort_along_batch(batch)\narray([[1, 4, 2],\n       [3, 6, 5]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.sum","title":"redcat.ba.sum","text":"<pre><code>sum(\n    a: TBatchedArray,\n    axis: SupportsIndex | None = None,\n    dtype: DTypeLike = None,\n    out: ndarray | None = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray | ndarray\n</code></pre> <p>Return the sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>axis</code> <code>SupportsIndex | None</code> <p>Axis along which the cumulative product is computed. By default, the input is flattened.</p> <code>None</code> <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>out</code> <code>ndarray | None</code> <p>Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output but the type will be cast if necessary.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray | ndarray</code> <p>The sum of elements along a given axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.sum(batch, axis=0)\narray([ 4, 10, 7])\n&gt;&gt;&gt; ba.sum(batch, axis=0, keepdims=True)\narray([[ 4, 10, 7]])\n&gt;&gt;&gt; batch = BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]), batch_axis=1)\n&gt;&gt;&gt; ba.sum(batch, axis=1)\narray([ 9, 12])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.sum_along_batch","title":"redcat.ba.sum_along_batch","text":"<pre><code>sum_along_batch(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    keepdims: bool = False,\n) -&gt; TBatchedArray\n</code></pre> <p>Return the sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The input array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Type of the returned array and of the accumulator in which the elements are summed. If dtype is not specified, it defaults to the dtype of <code>self</code>, unless a has an integer dtype with a precision less than that of  the default platform integer. In that case, the default platform integer is used.</p> <code>None</code> <code>keepdims</code> <code>bool</code> <p>If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the original array.</p> <code>False</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>The sum of elements along the batch axis treating Not a Numbers (NaNs) as zero.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.BatchedArray(np.array([[1, 6, 2], [3, 4, 5]]))\n&gt;&gt;&gt; ba.sum_along_batch(batch)\narray([ 4, 10, 7])\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.zeros","title":"redcat.ba.zeros","text":"<pre><code>zeros(\n    shape: int | Sequence[int],\n    dtype: DTypeLike = None,\n    order: str = \"C\",\n    *,\n    batch_axis: int = 0,\n    **kwargs: Any\n) -&gt; BatchedArray\n</code></pre> <p>Return a new array of given shape and type, filled with zeros.</p> <p>Equivalent of <code>numpy.zeros</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>int | Sequence[int]</code> <p>Shape of the new array, e.g., <code>(2, 3)</code> or <code>2</code>.</p> required <code>dtype</code> <code>DTypeLike</code> <p>The desired data-type for the array.</p> <code>None</code> <code>order</code> <code>str</code> <p>Whether to store multi-dimensional data in row-major (C-style) or column-major (Fortran-style) order in memory.</p> <code>'C'</code> <code>batch_axis</code> <code>int</code> <p>Specifies the batch axis in the array object.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>See the documentation of <code>numpy.zeros</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>BatchedArray</code> <p>An array object satisfying the specified requirements.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; batch = ba.zeros((2, 3))\n&gt;&gt;&gt; batch\narray([[0., 0., 0.],\n       [0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchedarray/#redcat.ba.zeros_like","title":"redcat.ba.zeros_like","text":"<pre><code>zeros_like(\n    a: TBatchedArray,\n    dtype: DTypeLike = None,\n    order: OrderACFK = \"K\",\n    subok: bool = True,\n    shape: ShapeLike = None,\n    batch_size: int | None = None,\n) -&gt; TBatchedArray\n</code></pre> <p>Return an array of zeros with the same shape and type as a given array.</p> <p>Equivalent of <code>numpy.zeros_like</code> for <code>BatchedArray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>TBatchedArray</code> <p>The shape and data-type of a define these same attributes of the returned array.</p> required <code>dtype</code> <code>DTypeLike</code> <p>Overrides the data type of the result.</p> <code>None</code> <code>order</code> <code>OrderACFK</code> <p>Overrides the memory layout of the result. 'C' means C-order, 'F' means F-order, 'A' means 'F' if <code>a</code> is Fortran contiguous, 'C' otherwise. 'K' means match the layout of <code>a</code> as closely as possible.</p> <code>'K'</code> <code>subok</code> <code>bool</code> <p>If True, then the newly created array will use the sub-class type of <code>a</code>, otherwise it will be a base-class array.</p> <code>True</code> <code>shape</code> <code>ShapeLike</code> <p>Overrides the shape of the result. If order='K' and the number of dimensions is unchanged, will try to keep order, otherwise, order='C' is implied.</p> <code>None</code> <code>batch_size</code> <code>int | None</code> <p>Overrides the batch size. If <code>None</code>, the batch size of the current batch is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>TBatchedArray</code> <p>Array of zeros with the same shape and type as <code>a</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat import ba\n&gt;&gt;&gt; array = ba.ones((2, 5))\n&gt;&gt;&gt; ba.zeros_like(array)\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]], batch_axis=0)\n&gt;&gt;&gt; ba.zeros_like(array, batch_size=5)\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]], batch_axis=0)\n</code></pre>"},{"location":"refs/batchlist/","title":"BatchList","text":""},{"location":"refs/batchlist/#redcat.BatchList","title":"redcat.BatchList","text":"<p>               Bases: <code>BaseBatch[list[T]]</code></p> <p>Implement a batch object to easily manipulate a list of examples.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[T]</code> <p>Specifies the list of examples.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>if the input is not a list.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import BatchList\n&gt;&gt;&gt; batch = BatchList([1, 2, 3])\n&gt;&gt;&gt; batch\nBatchList(data=[1, 2, 3])\n</code></pre>"},{"location":"refs/batchlist/#redcat.BatchList.apply","title":"redcat.BatchList.apply","text":"<pre><code>apply(fn: Callable[[T], T]) -&gt; Self\n</code></pre> <p>Apply a function to transform the element in the list of the current batch.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[[T], T]</code> <p>Specifies the function to be applied to the element in the list. It is the responsibility of the user to verify the function applies a valid transformation of the data.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The transformed batch.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import BatchList\n&gt;&gt;&gt; batch = BatchList([1, 2, 3])\n&gt;&gt;&gt; batch.apply(lambda val: val + 2)\nBatchList(data=[3, 4, 5])\n</code></pre>"},{"location":"refs/batchlist/#redcat.BatchList.apply_","title":"redcat.BatchList.apply_","text":"<pre><code>apply_(fn: Callable[[T], T]) -&gt; None\n</code></pre> <p>Apply a function to transform the element in the list of the current batch.</p> <p>In-place version of <code>apply</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[[T], T]</code> <p>Specifies the function to be applied to the element in the list. It is the responsibility of the user to verify the function applies a valid transformation of the data.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import BatchList\n&gt;&gt;&gt; batch = BatchList([1, 2, 3])\n&gt;&gt;&gt; batch.apply_(lambda val: val + 2)\n&gt;&gt;&gt; batch\nBatchList(data=[3, 4, 5])\n</code></pre>"},{"location":"refs/datapipes/","title":"DataPipes","text":""},{"location":"refs/datapipes/#redcat.datapipes.iter","title":"redcat.datapipes.iter","text":"<p>Contain the implementation of <code>IterDataPipe</code>s.</p>"},{"location":"refs/datapipes/#redcat.datapipes.iter.BatchExtender","title":"redcat.datapipes.iter.BatchExtender","text":"<p>               Bases: <code>IterDataPipe[BaseBatch[T]]</code></p> <p>Implement a DataPipe to combine several <code>BaseBatch</code> object into a single <code>BaseBatch</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>datapipe</code> <code>IterDataPipe[BaseBatch[T]]</code> <p>Specifies the source DataPipe. The DataPipe has to return compatible <code>BaseBatch</code> objects.</p> required <code>buffer_size</code> <code>int</code> <p>Specifies the buffer size i.e. the number of batches that are combined into a bigger batch.</p> <code>10</code> <code>drop_last</code> <code>bool</code> <p>If <code>True</code>, the last samples are dropped if the buffer is not full, otherwise it is returned.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from torch.utils.data.datapipes.iter import IterableWrapper\n&gt;&gt;&gt; from redcat import BatchedTensor\n&gt;&gt;&gt; from redcat.datapipes.iter import BatchExtender\n&gt;&gt;&gt; datapipe = BatchExtender(\n...     IterableWrapper([BatchedTensor(torch.ones(2) * i) for i in range(10)]),\n...     buffer_size=4,\n... )\n&gt;&gt;&gt; list(datapipe)\n[tensor([0., 0., 1., 1., 2., 2., 3., 3.], batch_dim=0),\n tensor([4., 4., 5., 5., 6., 6., 7., 7.], batch_dim=0),\n tensor([8., 8., 9., 9.], batch_dim=0)]\n&gt;&gt;&gt; datapipe = BatchExtender(\n...     IterableWrapper([BatchedTensor(torch.ones(2) * i) for i in range(10)]),\n...     buffer_size=4,\n...     drop_last=True,\n... )\n&gt;&gt;&gt; list(datapipe)\n[tensor([0., 0., 1., 1., 2., 2., 3., 3.], batch_dim=0),\n tensor([4., 4., 5., 5., 6., 6., 7., 7.], batch_dim=0)]\n</code></pre>"},{"location":"refs/datapipes/#redcat.datapipes.iter.BatchShuffler","title":"redcat.datapipes.iter.BatchShuffler","text":"<p>               Bases: <code>IterDataPipe[BaseBatch[T]]</code></p> <p>Implement a DataPipe to shuffle data in <code>BaseBatch</code> objects.</p> <p>Parameters:</p> Name Type Description Default <code>datapipe</code> <code>IterDataPipe[BaseBatch[T]]</code> <p>Specifies the source DataPipe. The DataPipe has to return <code>BaseBatch</code> objects.</p> required <code>random_seed</code> <code>int</code> <p>Specifies the random seed used to shuffle the data.</p> <code>3770589329299158004</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from torch.utils.data.datapipes.iter import IterableWrapper\n&gt;&gt;&gt; from redcat import BatchedTensor\n&gt;&gt;&gt; from redcat.datapipes.iter import BatchShuffler\n&gt;&gt;&gt; datapipe = BatchShuffler(\n...     IterableWrapper([BatchedTensor(torch.arange(4).add(i)) for i in range(2)])\n... )\n&gt;&gt;&gt; list(datapipe)\n[tensor([3, 0, 1, 2], batch_dim=0), tensor([1, 3, 4, 2], batch_dim=0)]\n</code></pre>"},{"location":"refs/datapipes/#redcat.datapipes.iter.BatchShuffler.random_seed","title":"redcat.datapipes.iter.BatchShuffler.random_seed  <code>property</code>","text":"<pre><code>random_seed: int\n</code></pre> <p>The random seed used to initialize the pseudo random generator.</p>"},{"location":"refs/datapipes/#redcat.datapipes.iter.MiniBatcher","title":"redcat.datapipes.iter.MiniBatcher","text":"<p>               Bases: <code>IterDataPipe[BaseBatch[T]]</code></p> <p>Implement a DataPipe to generate mini-batches from a batch (<code>BaseBatch</code> object).</p> <p>Parameters:</p> Name Type Description Default <code>datapipe_or_batch</code> <code>IterDataPipe[BaseBatch[T]] | BaseBatch[T]</code> <p>Specifies the datapipe of batches to split. The generated mini-batches have the same structure as the input batches.</p> required <code>batch_size</code> <code>int</code> <p>Specifies the batch size.</p> required <code>drop_last</code> <code>bool</code> <p>If <code>True</code>, it drops the last incomplete batch, if the number of examples is not divisible by the batch size. If <code>False</code> and the number of examples is not divisible by the batch size, then the last batch will be smaller.</p> <code>False</code> <code>shuffle</code> <code>bool</code> <p>If <code>True</code>, the batches are shuffled before to create the mini-batches. The shuffling is done per batch.</p> <code>False</code> <code>random_seed</code> <code>int</code> <p>Specifies the random seed used to shuffle the batch before to split it.</p> <code>5513175564631803238</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from torch.utils.data.datapipes.iter import IterableWrapper\n&gt;&gt;&gt; from redcat import BatchedTensor\n&gt;&gt;&gt; from redcat.datapipes.iter import MiniBatcher\n&gt;&gt;&gt; datapipe = MiniBatcher(\n...     IterableWrapper([BatchedTensor(torch.arange(4).add(i * 4)) for i in range(2)]),\n...     batch_size=2,\n... )\n&gt;&gt;&gt; list(datapipe)\n[tensor([0, 1], batch_dim=0),\n tensor([2, 3], batch_dim=0),\n tensor([4, 5], batch_dim=0),\n tensor([6, 7], batch_dim=0)]\n&gt;&gt;&gt; datapipe = MiniBatcher(BatchedTensor(torch.arange(9)), batch_size=2)\n&gt;&gt;&gt; list(datapipe)\n[tensor([0, 1], batch_dim=0),\n tensor([2, 3], batch_dim=0),\n tensor([4, 5], batch_dim=0),\n tensor([6, 7], batch_dim=0),\n tensor([8], batch_dim=0)]\n</code></pre>"},{"location":"refs/datapipes/#redcat.datapipes.iter.MiniBatcher.batch_size","title":"redcat.datapipes.iter.MiniBatcher.batch_size  <code>property</code>","text":"<pre><code>batch_size: int\n</code></pre> <p>The batch size.</p>"},{"location":"refs/datapipes/#redcat.datapipes.iter.MiniBatcher.random_seed","title":"redcat.datapipes.iter.MiniBatcher.random_seed  <code>property</code>","text":"<pre><code>random_seed: int\n</code></pre> <p>The random seed used to initialize the pseudo random generator.</p>"},{"location":"refs/utils/","title":"Utility functions","text":""},{"location":"refs/utils/#redcat.utils.array","title":"redcat.utils.array","text":"<p>Contain utility functions for <code>numpy.ndarray</code>s.</p>"},{"location":"refs/utils/#redcat.utils.array.arrays_share_data","title":"redcat.utils.array.arrays_share_data","text":"<pre><code>arrays_share_data(x: ndarray, y: ndarray) -&gt; bool\n</code></pre> <p>Indicate if two arrays share the same data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Specifies the first array.</p> required <code>y</code> <code>ndarray</code> <p>Specifies the second array.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two arrays share the same data, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.utils.array import arrays_share_data\n&gt;&gt;&gt; x = np.ones((2, 3))\n&gt;&gt;&gt; arrays_share_data(x, x)\nTrue\n&gt;&gt;&gt; arrays_share_data(x, x.copy())\nFalse\n&gt;&gt;&gt; y = x[1:]\n&gt;&gt;&gt; arrays_share_data(x, y)\nTrue\n</code></pre>"},{"location":"refs/utils/#redcat.utils.array.get_data_base","title":"redcat.utils.array.get_data_base","text":"<pre><code>get_data_base(array: ndarray) -&gt; ndarray\n</code></pre> <p>Return the base array that owns the actual data.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Specifies the input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The array that owns the actual data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.utils.array import get_data_base\n&gt;&gt;&gt; x = np.ones((2, 3))\n&gt;&gt;&gt; get_data_base(x)\narray([[1., 1., 1.],\n       [1., 1., 1.]])\n&gt;&gt;&gt; y = x[1:]\n&gt;&gt;&gt; get_data_base(y)\narray([[1., 1., 1.],\n       [1., 1., 1.]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.array.get_div_rounding_operator","title":"redcat.utils.array.get_div_rounding_operator","text":"<pre><code>get_div_rounding_operator(mode: str | None) -&gt; Callable\n</code></pre> <p>Get the rounding operator for a division.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str | None</code> <p>Specifies the type of rounding applied to the result. - <code>None</code>: true division. - <code>\"floor\"</code>: floor division.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>The rounding operator for a division</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.array import get_div_rounding_operator\n&gt;&gt;&gt; get_div_rounding_operator(None)\n&lt;ufunc 'divide'&gt;\n</code></pre>"},{"location":"refs/utils/#redcat.utils.array.permute_along_axis","title":"redcat.utils.array.permute_along_axis","text":"<pre><code>permute_along_axis(\n    array: ndarray, permutation: ndarray, axis: int = 0\n) -&gt; ndarray\n</code></pre> <p>Permutes the values of a array along a given axis.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>Specifies the array to permute.</p> required <code>permutation</code> <code>ndarray</code> <p>Specifies the permutation to use on the array. The dimension of this array should be compatible with the shape of the array to permute.</p> required <code>axis</code> <code>int</code> <p>Specifies the axis used to permute the array.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The permuted array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.utils.array import permute_along_axis\n&gt;&gt;&gt; permute_along_axis(np.arange(4), permutation=np.array([0, 2, 1, 3]))\narray([0, 2, 1, 3])\n&gt;&gt;&gt; permute_along_axis(\n...     np.arange(20).reshape(4, 5),\n...     permutation=np.array([0, 2, 1, 3]),\n... )\narray([[ 0,  1,  2,  3,  4],\n       [10, 11, 12, 13, 14],\n       [ 5,  6,  7,  8,  9],\n       [15, 16, 17, 18, 19]])\n&gt;&gt;&gt; permute_along_axis(\n...     np.arange(20).reshape(4, 5),\n...     permutation=np.array([0, 4, 2, 1, 3]),\n...     axis=1,\n... )\narray([[ 0,  4,  2,  1,  3],\n       [ 5,  9,  7,  6,  8],\n       [10, 14, 12, 11, 13],\n       [15, 19, 17, 16, 18]])\n&gt;&gt;&gt; permute_along_axis(\n...     np.arange(20).reshape(2, 2, 5),\n...     permutation=np.array([0, 4, 2, 1, 3]),\n...     axis=2,\n... )\narray([[[ 0,  4,  2,  1,  3],\n        [ 5,  9,  7,  6,  8]],\n       [[10, 14, 12, 11, 13],\n        [15, 19, 17, 16, 18]]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.array.to_array","title":"redcat.utils.array.to_array","text":"<pre><code>to_array(\n    data: BaseBatch | Sequence | Tensor | ndarray,\n) -&gt; ndarray\n</code></pre> <p>Convert the input to a <code>numpy.ndarray</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BaseBatch | Sequence | Tensor | ndarray</code> <p>Specifies the data to convert to an array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy array.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.array import to_array\n&gt;&gt;&gt; x = to_array([1, 2, 3, 4, 5])\n&gt;&gt;&gt; x\narray([1, 2, 3, 4, 5])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.collection","title":"redcat.utils.collection","text":"<p>Contain utility functions for collection objects.</p>"},{"location":"refs/utils/#redcat.utils.collection.to_list","title":"redcat.utils.collection.to_list","text":"<pre><code>to_list(\n    data: list | tuple | Tensor | ndarray | BaseBatch,\n) -&gt; list\n</code></pre> <p>Convert an input data to a list.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list | tuple | Tensor | ndarray | BaseBatch</code> <p>Specifies the data to convert.</p> required <p>Returns:</p> Type Description <code>list</code> <p>The data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat import BatchList\n&gt;&gt;&gt; from redcat.utils.collection import to_list\n&gt;&gt;&gt; to_list(BatchList([1, 2, 3]))\n[1, 2, 3]\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common","title":"redcat.utils.common","text":"<p>Contain utility functions.</p>"},{"location":"refs/utils/#redcat.utils.common.check_batch_dims","title":"redcat.utils.common.check_batch_dims","text":"<pre><code>check_batch_dims(dims: set[int]) -&gt; None\n</code></pre> <p>Get the batch dimensions from the inputs.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>set[int]</code> <p>Specifies the batch dims to check.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if there are more than one batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.common import check_batch_dims\n&gt;&gt;&gt; check_batch_dims({0})\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.check_data_and_dim","title":"redcat.utils.common.check_data_and_dim","text":"<pre><code>check_data_and_dim(\n    data: ndarray | Tensor, batch_dim: int\n) -&gt; None\n</code></pre> <p>Check if the array <code>data</code> and <code>batch_dim</code> are correct.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray | Tensor</code> <p>Specifies the array in the batch.</p> required <code>batch_dim</code> <code>int</code> <p>Specifies the batch dimension in the array object.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if one of the input is incorrect.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.common import check_data_and_dim\n&gt;&gt;&gt; check_data_and_dim(np.ones((2, 3)), batch_dim=0)\n&gt;&gt;&gt; check_data_and_dim(torch.ones(2, 3), batch_dim=0)\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.check_seq_dims","title":"redcat.utils.common.check_seq_dims","text":"<pre><code>check_seq_dims(dims: set[int]) -&gt; None\n</code></pre> <p>Get the sequence dimensions from the inputs.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>set[int]</code> <p>Specifies the sequence dims to check.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if there are more than one sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.common import check_seq_dims\n&gt;&gt;&gt; check_seq_dims({1})\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.get_batch_dims","title":"redcat.utils.common.get_batch_dims","text":"<pre><code>get_batch_dims(\n    args: Iterable[Any],\n    kwargs: Mapping[str, Any] | None = None,\n) -&gt; set[int]\n</code></pre> <p>Get the batch dimensions from the inputs.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Iterable[Any]</code> <p>Variable length argument list.</p> required <code>kwargs</code> <code>Mapping[str, Any] | None</code> <p>Arbitrary keyword arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>set[int]</code> <p>The batch dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchedTensor\n&gt;&gt;&gt; from redcat.utils.common import get_batch_dims\n&gt;&gt;&gt; get_batch_dims(\n...     args=(BatchedTensor(torch.ones(2, 3)), BatchedTensor(torch.ones(2, 6))),\n...     kwargs={\"batch\": BatchedTensor(torch.ones(2, 4))},\n... )\n{0}\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.get_data","title":"redcat.utils.common.get_data","text":"<pre><code>get_data(data: BaseBatch[T] | Any) -&gt; T\n</code></pre> <p>Get the data from a batch or the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BaseBatch[T] | Any</code> <p>Specifies the data.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The data.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchedTensor\n&gt;&gt;&gt; from redcat.ba import BatchedArray\n&gt;&gt;&gt; from redcat.utils.common import get_data\n&gt;&gt;&gt; get_data(BatchedArray(np.ones((2, 3))))\narray([[1., 1., 1.],\n       [1., 1., 1.]])\n&gt;&gt;&gt; get_data(BatchedTensor(torch.ones(2, 3)))\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n&gt;&gt;&gt; get_data(torch.ones(2, 3))\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.get_seq_dims","title":"redcat.utils.common.get_seq_dims","text":"<pre><code>get_seq_dims(\n    args: Iterable[Any, ...],\n    kwargs: Mapping[str, Any] | None = None,\n) -&gt; set[int]\n</code></pre> <p>Get the sequence dimensions from the inputs.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Iterable[Any, ...]</code> <p>Variable length argument list.</p> required <code>kwargs</code> <code>Mapping[str, Any] | None</code> <p>Arbitrary keyword arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>set[int]</code> <p>The sequence dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat import BatchedTensorSeq\n&gt;&gt;&gt; from redcat.utils.common import get_seq_dims\n&gt;&gt;&gt; get_seq_dims(\n...     args=(BatchedTensorSeq(torch.ones(2, 3)), BatchedTensorSeq(torch.ones(2, 6))),\n...     kwargs={\"batch\": BatchedTensorSeq(torch.ones(2, 4))},\n... )\n{1}\n</code></pre>"},{"location":"refs/utils/#redcat.utils.common.swap2","title":"redcat.utils.common.swap2","text":"<pre><code>swap2(sequence: Tensor, index0: int, index1: int) -&gt; Tensor\n</code></pre><pre><code>swap2(\n    sequence: ndarray, index0: int, index1: int\n) -&gt; ndarray\n</code></pre><pre><code>swap2(\n    sequence: MutableSequence, index0: int, index1: int\n) -&gt; MutableSequence\n</code></pre> <pre><code>swap2(\n    sequence: Tensor | ndarray | MutableSequence,\n    index0: int,\n    index1: int,\n) -&gt; Tensor | ndarray | MutableSequence\n</code></pre> <p>Swap two values in a mutable sequence.</p> <p>The swap is performed in-place.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Tensor | ndarray | MutableSequence</code> <p>Specifies the sequence to update.</p> required <code>index0</code> <code>int</code> <p>Specifies the index of the first value to swap.</p> required <code>index1</code> <code>int</code> <p>Specifies the index of the second value to swap.</p> required <p>Returns:</p> Type Description <code>Tensor | ndarray | MutableSequence</code> <p>The updated sequence.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.common import swap2\n&gt;&gt;&gt; seq = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; swap2(seq, 2, 0)\n&gt;&gt;&gt; seq\n[3, 2, 1, 4, 5]\n</code></pre>"},{"location":"refs/utils/#redcat.utils.random","title":"redcat.utils.random","text":"<p>Contain utility functions to manage randomness.</p>"},{"location":"refs/utils/#redcat.utils.random.get_random_rng","title":"redcat.utils.random.get_random_rng","text":"<pre><code>get_random_rng(\n    rng_or_seed: Random | int | None = None,\n) -&gt; Random\n</code></pre> <p>Get a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>rng_or_seed</code> <code>Random | int | None</code> <p>Specifies the pseudorandom number generator for sampling or the random seed for the random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Random</code> <p>The initialized random number generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.random import get_random_rng\n&gt;&gt;&gt; get_random_rng(42)\n&lt;random.Random object at 0x...&gt;\n</code></pre>"},{"location":"refs/utils/#redcat.utils.random.randperm","title":"redcat.utils.random.randperm","text":"<pre><code>randperm(n: int, rng: Generator) -&gt; ndarray\n</code></pre><pre><code>randperm(n: int, rng: Generator) -&gt; Tensor\n</code></pre><pre><code>randperm(\n    n: int, generator: Random | int | None = None\n) -&gt; list[int]\n</code></pre> <pre><code>randperm(\n    n: int, rng_or_seed: RNGType | int | None = None\n) -&gt; Tensor | ndarray | list[int]\n</code></pre> <p>Create a random permutation of integers from <code>0</code> to <code>n - 1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Specifies the number of items.</p> required <code>rng_or_seed</code> <code>RNGType | int | None</code> <p>Specifies the pseudorandom number generator for sampling or the random seed for the random number generator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor | ndarray | list[int]</code> <p>A random permutation of integers from <code>0</code> to <code>n - 1</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from redcat.utils.random import randperm\n&gt;&gt;&gt; randperm(10, np.random.default_rng(42))\narray([...])\n</code></pre> <pre><code>&gt;&gt;&gt; from redcat.utils.tensor import get_torch_generator\n&gt;&gt;&gt; from redcat.utils.random import randperm\n&gt;&gt;&gt; randperm(10, get_torch_generator(42))\ntensor([...])\n</code></pre> <pre><code>&gt;&gt;&gt; from redcat.utils.random import randperm\n&gt;&gt;&gt; randperm(10, 42)\n[...]\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor","title":"redcat.utils.tensor","text":"<p>Contain utility functions for <code>torch.Tensor</code>s.</p>"},{"location":"refs/utils/#redcat.utils.tensor.align_to_batch_first","title":"redcat.utils.tensor.align_to_batch_first","text":"<pre><code>align_to_batch_first(\n    tensor: Tensor, batch_dim: int\n) -&gt; Tensor\n</code></pre> <p>Aligns the input tensor format to <code>(batch_size, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Specifies the tensor to change format.</p> required <code>batch_dim</code> <code>int</code> <p>Specifies the batch dimension in the input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(batch_size, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.tensor import align_to_batch_first\n&gt;&gt;&gt; align_to_batch_first(torch.arange(20).view(4, 5), batch_dim=1)\ntensor([[ 0,  5, 10, 15],\n        [ 1,  6, 11, 16],\n        [ 2,  7, 12, 17],\n        [ 3,  8, 13, 18],\n        [ 4,  9, 14, 19]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.align_to_batch_seq","title":"redcat.utils.tensor.align_to_batch_seq","text":"<pre><code>align_to_batch_seq(\n    tensor: Tensor, batch_dim: int, seq_dim: int\n) -&gt; Tensor\n</code></pre> <p>Aligns the input tensor format to <code>(batch_size, sequence_length, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Specifies the tensor to change format.</p> required <code>batch_dim</code> <code>int</code> <p>Specifies the batch dimension in the input tensor.</p> required <code>seq_dim</code> <code>int</code> <p>Specifies the sequence dimension in the input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(batch_size, sequence_length, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.tensor import align_to_batch_seq\n&gt;&gt;&gt; align_to_batch_seq(torch.arange(20).view(4, 5), batch_dim=1, seq_dim=0)\ntensor([[ 0,  5, 10, 15],\n        [ 1,  6, 11, 16],\n        [ 2,  7, 12, 17],\n        [ 3,  8, 13, 18],\n        [ 4,  9, 14, 19]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.align_to_seq_batch","title":"redcat.utils.tensor.align_to_seq_batch","text":"<pre><code>align_to_seq_batch(\n    tensor: Tensor, batch_dim: int, seq_dim: int\n) -&gt; Tensor\n</code></pre> <p>Aligns the input tensor format to <code>(sequence_length, batch_size, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Specifies the tensor to change format.</p> required <code>batch_dim</code> <code>int</code> <p>Specifies the batch dimension in the input tensor.</p> required <code>seq_dim</code> <code>int</code> <p>Specifies the sequence dimension in the input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape <code>(sequence_length, batch_size, *)</code> where <code>*</code> means any number of dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.tensor import align_to_seq_batch\n&gt;&gt;&gt; align_to_seq_batch(torch.arange(20).view(4, 5), batch_dim=0, seq_dim=1)\ntensor([[ 0,  5, 10, 15],\n        [ 1,  6, 11, 16],\n        [ 2,  7, 12, 17],\n        [ 3,  8, 13, 18],\n        [ 4,  9, 14, 19]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.compute_batch_seq_permutation","title":"redcat.utils.tensor.compute_batch_seq_permutation","text":"<pre><code>compute_batch_seq_permutation(\n    num_dims: int,\n    old_batch_dim: int,\n    old_seq_dim: int,\n    new_batch_dim: int,\n    new_seq_dim: int,\n) -&gt; list[int]\n</code></pre> <p>Compute the permutation to update the batch and sequence dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>num_dims</code> <code>int</code> <p>Specifies the number of dimensions.</p> required <code>old_batch_dim</code> <code>int</code> <p>Specifies the old batch dimension.</p> required <code>old_seq_dim</code> <code>int</code> <p>Specifies the old sequence dimension.</p> required <code>new_batch_dim</code> <code>int</code> <p>Specifies the new batch dimension.</p> required <code>new_seq_dim</code> <code>int</code> <p>Specifies the new sequence dimension.</p> required <p>Returns:</p> Type Description <code>list[int]</code> <p>The permutation to update the batch and sequence dimensions.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.tensor import compute_batch_seq_permutation\n&gt;&gt;&gt; compute_batch_seq_permutation(5, 0, 1, 1, 0)\n[1, 0, 2, 3, 4]\n&gt;&gt;&gt; compute_batch_seq_permutation(2, 0, 1, 1, 0)\n[1, 0]\n&gt;&gt;&gt; compute_batch_seq_permutation(5, 0, 1, 2, 0)\n[1, 2, 0, 3, 4]\n&gt;&gt;&gt; compute_batch_seq_permutation(5, 0, 1, 1, 2)\n[2, 0, 1, 3, 4]\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.get_torch_generator","title":"redcat.utils.tensor.get_torch_generator","text":"<pre><code>get_torch_generator(\n    random_seed: int = 1,\n    device: device | str | None = \"cpu\",\n) -&gt; Generator\n</code></pre> <p>Create a <code>torch.Generator</code> initialized with a given seed.</p> <p>Parameters:</p> Name Type Description Default <code>random_seed</code> <code>int</code> <p>Specifies a random seed.</p> <code>1</code> <code>device</code> <code>device | str | None</code> <p>Specifies the desired device for the generator.</p> <code>'cpu'</code> <p>Returns:</p> Type Description <code>Generator</code> <p>A PyTorch pseudo random number generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.tensor import get_torch_generator\n&gt;&gt;&gt; generator = get_torch_generator(42)\n&gt;&gt;&gt; torch.rand(2, 4, generator=generator)\ntensor([[...]])\n&gt;&gt;&gt; generator = get_torch_generator(42)\n&gt;&gt;&gt; torch.rand(2, 4, generator=generator)\ntensor([[...]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.permute_along_dim","title":"redcat.utils.tensor.permute_along_dim","text":"<pre><code>permute_along_dim(\n    tensor: Tensor, permutation: Tensor, dim: int = 0\n) -&gt; Tensor\n</code></pre> <p>Permutes the values of a tensor along a given dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Specifies the tensor to permute.</p> required <code>permutation</code> <code>Tensor</code> <p>Specifies the permutation to use on the tensor. The dimension of this tensor should be compatible with the shape of the tensor to permute.</p> required <code>dim</code> <code>int</code> <p>Specifies the dimension used to permute the tensor.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The permuted tensor.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from redcat.utils.tensor import permute_along_dim\n&gt;&gt;&gt; permute_along_dim(tensor=torch.arange(4), permutation=torch.tensor([0, 2, 1, 3]))\ntensor([0, 2, 1, 3])\n&gt;&gt;&gt; permute_along_dim(\n...     tensor=torch.arange(20).view(4, 5),\n...     permutation=torch.tensor([0, 2, 1, 3]),\n... )\ntensor([[ 0,  1,  2,  3,  4],\n        [10, 11, 12, 13, 14],\n        [ 5,  6,  7,  8,  9],\n        [15, 16, 17, 18, 19]])\n&gt;&gt;&gt; permute_along_dim(\n...     tensor=torch.arange(20).view(4, 5),\n...     permutation=torch.tensor([0, 4, 2, 1, 3]),\n...     dim=1,\n... )\ntensor([[ 0,  4,  2,  1,  3],\n        [ 5,  9,  7,  6,  8],\n        [10, 14, 12, 11, 13],\n        [15, 19, 17, 16, 18]])\n&gt;&gt;&gt; permute_along_dim(\n...     tensor=torch.arange(20).view(2, 2, 5),\n...     permutation=torch.tensor([0, 4, 2, 1, 3]),\n...     dim=2,\n... )\ntensor([[[ 0,  4,  2,  1,  3],\n         [ 5,  9,  7,  6,  8]],\n        [[10, 14, 12, 11, 13],\n         [15, 19, 17, 16, 18]]])\n</code></pre>"},{"location":"refs/utils/#redcat.utils.tensor.to_tensor","title":"redcat.utils.tensor.to_tensor","text":"<pre><code>to_tensor(\n    data: BaseBatch | Sequence | Tensor | ndarray,\n) -&gt; Tensor\n</code></pre> <p>Convert the input to a <code>torch.Tensor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>BaseBatch | Sequence | Tensor | ndarray</code> <p>Specifies the data to convert to a tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from redcat.utils.tensor import to_tensor\n&gt;&gt;&gt; x = to_tensor([1, 2, 3, 4, 5])\n&gt;&gt;&gt; x\ntensor([1, 2, 3, 4, 5])\n</code></pre>"}]}